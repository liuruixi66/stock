#æ³¨æ„ï¼šæ­¤æ–‡ä»¶å¥½å¤šå­—æ®µæ˜¯éšæœºç”Ÿæˆçš„ï¼Œå¯èƒ½ä¸ç¬¦åˆå®é™…æ•°æ®
# éœ€è¦æ ¹æ®å®é™…æ•°æ®ç»“æ„è°ƒæ•´å­—æ®µå
#0,1,2,3,4,5,6,7,8,9,10,11,12,13,14æ˜¯å¯¹åº”ç€é‡‘å‰ï¼Œæ­»å‰ï¼Œè‚¡ä¸œå‡æŒä¿¡å·ï¼Œè‚¡ä¸œå¢æŒä¿¡å·ï¼Œè‚¡ä¸œåˆ†çº¢ä¿¡å·ï¼Œè¿è§„é—®è¯¢å‡½ä¿¡å·ï¼Œæ–°ä¸Šå¸‚ï¼ŒåŒ—äº¤æ‰€ï¼Œæ²ªæ·±ä¸»æ¿ï¼ŒSTï¼Œ*STï¼Œåœç‰Œï¼Œç§‘åˆ›æ¿ï¼Œåˆ›ä¸šæ¿ï¼Œé€€å¸‚ã€‚
# ä¹°å…¥ä¿¡å·(15)å’Œå–å‡ºä¿¡å·(16)å·²ç§»è‡³signal_library.py

import sys
import os
import pandas as pd
from datetime import datetime, timedelta
from sqlalchemy import create_engine
from indicator_utils import resample_to_period
import compare
# å¯¼å…¥ä¿¡å·åº“
from signal_library import SIGNAL_CODES, generate_buy_signal, generate_sell_signal
# å¯¼å…¥æŒ‡æ ‡æ¨¡å—
from indicators import (
    analyze_macd_divergence,
    analyze_kdj_divergence,
    analyze_trend_signals,
    MarketAnalyzer,
    get_market_analysis_summary
)
# Django API è§†å›¾ï¼Œæ”¯æŒå‰ç«¯ POST è°ƒç”¨
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
import json

# Django ç›¸å…³å¯¼å…¥
try:
    import django
    import sys
    
    # ç¡®ä¿æ­£ç¡®çš„è·¯å¾„
    backend_dir = os.path.dirname(os.path.abspath(__file__))
    if backend_dir not in sys.path:
        sys.path.insert(0, backend_dir)
    
    # è®¾ç½®Djangoé…ç½®
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'myproject.settings')
    
    # åˆ‡æ¢åˆ°backendç›®å½•ç¡®ä¿Djangoæ­£ç¡®åˆå§‹åŒ–
    original_cwd = os.getcwd()
    os.chdir(backend_dir)
    
    django.setup()
    from stockmarket.models import StockSpot, StockHistoryData
    from django.db.models import Q
    
    # æ¢å¤åŸæ¥çš„å·¥ä½œç›®å½•
    os.chdir(original_cwd)
    
    DJANGO_AVAILABLE = True
    print(f"âœ… Djangoé…ç½®æˆåŠŸï¼Œbackendç›®å½•: {backend_dir}")
except Exception as e:
    DJANGO_AVAILABLE = False
    print(f"âŒ Djangoé…ç½®å¤±è´¥: {str(e)}")
    print("å°†ä½¿ç”¨CSVæ–‡ä»¶æ¨¡å¼")

def filter_stocks_from_database(indicator_names, conditions, start_date=None, end_date=None, limit=100, extra_params=None):
    """
    ä»æ•°æ®åº“ç­›é€‰è‚¡ç¥¨æ•°æ®
    
    Args:
        indicator_names: æŒ‡æ ‡åç§°åˆ—è¡¨
        conditions: ç­›é€‰æ¡ä»¶å­—å…¸
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
        extra_params: é¢å¤–å‚æ•°ï¼ˆåŒ…å«å¯ç”¨æŒ‡æ ‡ã€å‘¨æœŸç­‰ï¼‰
    
    Returns:
        pandas.DataFrame: ç­›é€‰åçš„è‚¡ç¥¨æ•°æ®
    """
    if not DJANGO_AVAILABLE:
        print("Djangoä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤CSVæ–‡ä»¶æ¨¡å¼")
        print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
        try:
            result = filter_stocks(indicator_names, conditions, '/home/liu/æ¡Œé¢/stock-main/backend/000001_10years.csv')
            if isinstance(result, pd.DataFrame):
                return result
            else:
                print(f"âŒ CSVæ¨¡å¼è¿”å›éDataFrame: {type(result)}")
                return pd.DataFrame()
        except Exception as e:
            print(f"âŒ CSVæ¨¡å¼ç­›é€‰å¤±è´¥: {e}")
            return pd.DataFrame()
    
    try:
        # è·å–é¢å¤–å‚æ•°
        if extra_params is None:
            extra_params = {}
            
        enabled_indicators = extra_params.get('enabled_indicators', indicator_names)
        period = extra_params.get('period', 'æ—¥')
        data_frequency = extra_params.get('data_frequency', 'daily')
        minute_interval = extra_params.get('minute_interval', '5')
        initial_capital = extra_params.get('initial_capital', 100000)
        
        print(f"æ•°æ®åº“ç­›é€‰ - å¯ç”¨æŒ‡æ ‡: {enabled_indicators}, å‘¨æœŸ: {period}")
        print(f"æ•°æ®é¢‘ç‡: {data_frequency}, åˆ†é’Ÿå‘¨æœŸ: {minute_interval}, åˆå§‹èµ„é‡‘: {initial_capital}")
        
        # æ ¹æ®æ•°æ®é¢‘ç‡é€‰æ‹©ä¸åŒçš„æ•°æ®æºå’Œå¤„ç†æ–¹å¼
        if data_frequency == 'minute':
            print(f"ä½¿ç”¨åˆ†é’Ÿçº§æ•°æ®ï¼Œå‘¨æœŸ: {minute_interval}åˆ†é’Ÿ")
            # è¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºå¤„ç†åˆ†é’Ÿæ•°æ®çš„é€»è¾‘
            # å½“å‰ä½¿ç”¨æ—¥çº¿æ•°æ®æ¨¡æ‹Ÿ
        elif data_frequency == 'tick':
            print("ä½¿ç”¨tickçº§æ•°æ®")
            # è¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºå¤„ç†tickæ•°æ®çš„é€»è¾‘
            # å½“å‰ä½¿ç”¨æ—¥çº¿æ•°æ®æ¨¡æ‹Ÿ
        else:
            print("ä½¿ç”¨æ—¥çº¿æ•°æ®")
        
        # æ„å»ºæŸ¥è¯¢é›†ï¼Œä½¿ç”¨StockHistoryDataæ¨¡å‹
        queryset = StockHistoryData.objects.all()
        
        # æ—¥æœŸç­›é€‰
        if start_date:
            if isinstance(start_date, str):
                start_date = datetime.strptime(start_date.replace('-', ''), '%Y%m%d').date()
            queryset = queryset.filter(date__gte=start_date)
        
        if end_date:
            if isinstance(end_date, str):
                end_date = datetime.strptime(end_date.replace('-', ''), '%Y%m%d').date()
            queryset = queryset.filter(date__lte=end_date)
        
        # è½¬æ¢ä¸ºDataFrame
        fields = [
            'date', 'symbol', 'open', 'close', 'high', 'low',
            'volume', 'turnover', 'amplitude', 'pct_change', 'change', 'turnover_rate'
        ]
        
        data = list(queryset.values(*fields))
        if not data:
            print("æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°æ•°æ®")
            return pd.DataFrame()
        
        df = pd.DataFrame(data)
        
        # æ·»åŠ nameå­—æ®µï¼Œä½¿ç”¨symbolä½œä¸ºnameï¼ˆå› ä¸ºæ˜¾ç¤ºè‚¡ç¥¨ä»£ç ï¼‰
        df['name'] = df['symbol']
        
        # æ ‡å‡†åŒ–åˆ—åä»¥åŒ¹é…å›æµ‹ç³»ç»ŸæœŸæœ›çš„æ ¼å¼
        column_mapping = {
            'date': 'date',
            'symbol': 'code',  # å°†symbolæ˜ å°„ä¸ºcode
            'name': 'name',    # nameå­—æ®µç°åœ¨åŒ…å«è‚¡ç¥¨ä»£ç 
            'open': 'open',
            'close': 'close',
            'high': 'high', 
            'low': 'low',
            'volume': 'volume',
            'turnover': 'amount',  # å°†turnoveræ˜ å°„ä¸ºamount
            'pct_change': 'change_rate'  # å°†pct_changeæ˜ å°„ä¸ºchange_rate
        }
        
        # é‡å‘½ååˆ—
        df = df.rename(columns=column_mapping)
        
        # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
        required_columns = ['date', 'code', 'open', 'high', 'low', 'close', 'volume']
        for col in required_columns:
            if col not in df.columns:
                print(f"è­¦å‘Šï¼šç¼ºå°‘å¿…è¦åˆ— {col}")
        
        # ğŸ”„ åº”ç”¨å‘¨æœŸèšåˆ - å¿…é¡»åœ¨æŒ‡æ ‡è®¡ç®—ä¹‹å‰è¿›è¡Œ
        print(f"åº”ç”¨å‘¨æœŸèšåˆ: {period}")
        if period in ['weekly', 'å‘¨', 'W']:
            print("æ­£åœ¨è¿›è¡Œå‘¨çº¿èšåˆ...")
            df = aggregate_to_weekly(df, start_date, end_date)
        elif period in ['monthly', 'æœˆ', 'M']:
            print("æ­£åœ¨è¿›è¡Œæœˆçº¿èšåˆ...")
            df = aggregate_to_monthly(df, start_date, end_date)
        elif period in ['yearly', 'å¹´', 'Y']:
            print("æ­£åœ¨è¿›è¡Œå¹´çº¿èšåˆ...")
            df = aggregate_to_yearly(df, start_date, end_date)
        elif period in ['daily', 'æ—¥', 'D']:
            print("ä½¿ç”¨æ—¥çº¿æ•°æ®ï¼Œæ— éœ€èšåˆ")
            # å¯¹äºæ—¥çº¿æ•°æ®ï¼Œä»ç„¶éœ€è¦åº”ç”¨æ—¥æœŸèŒƒå›´ç­›é€‰
            if start_date or end_date:
                df['date'] = pd.to_datetime(df['date'])
                if start_date:
                    start_date_dt = pd.to_datetime(start_date)
                    df = df[df['date'] >= start_date_dt]
                if end_date:
                    end_date_dt = pd.to_datetime(end_date)
                    df = df[df['date'] <= end_date_dt]
        else:
            print(f"æœªçŸ¥å‘¨æœŸç±»å‹: {period}ï¼Œä½¿ç”¨æ—¥çº¿æ•°æ®")
        
        # è·å–è‡ªå®šä¹‰å‚æ•°
        macd_params = extra_params.get('macd_params', {})
        kdj_params = extra_params.get('kdj_params', {})
        ma_params = extra_params.get('ma_params', {})
        market_filter = extra_params.get('market', 'ALL')  # å¸‚åœºç­›é€‰å‚æ•°
        enable_divergence = extra_params.get('enable_divergence', True)  # æ˜¯å¦å¯ç”¨èƒŒç¦»åˆ†æ
        
        # å¸‚åœºç­›é€‰
        print(f"åº”ç”¨å¸‚åœºç­›é€‰: {market_filter}")
        if market_filter != 'ALL':
            # ä½¿ç”¨MarketAnalyzerè¿›è¡Œå¸‚åœºç­›é€‰
            stock_codes = df['code'].unique().tolist()
            print(f"ç­›é€‰å‰è‚¡ç¥¨ä»£ç : {stock_codes}")
            
            if market_filter.lower() in ['shanghai', 'sh', 'ä¸Šè¯']:
                filtered_codes = MarketAnalyzer.filter_stocks_by_market(stock_codes, 'shanghai')
                print(f"ä¸Šè¯ç­›é€‰ç»“æœ: {filtered_codes}")
            elif market_filter.lower() in ['shenzhen', 'sz', 'æ·±è¯']:
                filtered_codes = MarketAnalyzer.filter_stocks_by_market(stock_codes, 'shenzhen')
                print(f"æ·±è¯ç­›é€‰ç»“æœ: {filtered_codes}")
            else:
                filtered_codes = stock_codes  # ä¿æŒæ‰€æœ‰ä»£ç 
            
            # é‡è¦ä¿®å¤ï¼šå¦‚æœç­›é€‰åæ²¡æœ‰è‚¡ç¥¨ï¼Œç›´æ¥è¿”å›ç©ºç»“æœ
            if not filtered_codes:
                print(f"è­¦å‘Šï¼š{market_filter}å¸‚åœºç­›é€‰åæ— å¯ç”¨è‚¡ç¥¨ï¼Œè¿”å›ç©ºç»“æœ")
                return pd.DataFrame()
            
            df = df[df['code'].isin(filtered_codes)]
            print(f"å¸‚åœºç­›é€‰åå‰©ä½™ {len(df)} æ¡æ•°æ®")
        
        # é‡è¦æ£€æŸ¥ï¼šç¡®ä¿æœ‰æ•°æ®æ‰ç»§ç»­å¤„ç†
        if len(df) == 0:
            print("è­¦å‘Šï¼šç­›é€‰åæ— æ•°æ®ï¼Œè·³è¿‡æŒ‡æ ‡è®¡ç®—")
            return df
        
        # ğŸ“Š æ™ºèƒ½æŒ‡æ ‡è®¡ç®— - åªè®¡ç®—å‰ç«¯å¯ç”¨çš„æŒ‡æ ‡ï¼Œé¿å…ä¸å¿…è¦çš„è®¡ç®—å¼€é”€
        print(f"ğŸ”§ å¼€å§‹è®¡ç®—å¯ç”¨çš„æŒ‡æ ‡: {enabled_indicators}")
        calculated_indicators = []
        
        if 'ma' in enabled_indicators:
            print("ğŸ“ˆ æ­£åœ¨è®¡ç®—MA(ç§»åŠ¨å¹³å‡çº¿)æŒ‡æ ‡...")
            df = add_ma_indicators(df, **ma_params)
            calculated_indicators.append('MA')
        else:
            print("â­ï¸ MAæŒ‡æ ‡æœªå¯ç”¨ï¼Œè·³è¿‡è®¡ç®—")
            
        if 'macd' in enabled_indicators:
            print("ğŸ“Š æ­£åœ¨è®¡ç®—MACDæŒ‡æ ‡...")
            df = add_macd_indicators(df, **macd_params)
            calculated_indicators.append('MACD')
        else:
            print("â­ï¸ MACDæŒ‡æ ‡æœªå¯ç”¨ï¼Œè·³è¿‡è®¡ç®—")
            
        if 'kdj' in enabled_indicators:
            print("ğŸ“‰ æ­£åœ¨è®¡ç®—KDJæŒ‡æ ‡...")
            df = add_kdj_indicators(df, **kdj_params)
            calculated_indicators.append('KDJ')
        else:
            print("â­ï¸ KDJæŒ‡æ ‡æœªå¯ç”¨ï¼Œè·³è¿‡è®¡ç®—")
        
        # ğŸ¯ æ”¯æŒæ›´å¤šæŒ‡æ ‡ç±»å‹
        if 'rsi' in enabled_indicators:
            print("ğŸ“Š æ­£åœ¨è®¡ç®—RSIæŒ‡æ ‡...")
            df = add_rsi_indicators(df, **extra_params.get('rsi_params', {}))
            calculated_indicators.append('RSI')
        else:
            print("â­ï¸ RSIæŒ‡æ ‡æœªå¯ç”¨ï¼Œè·³è¿‡è®¡ç®—")
            
        if 'boll' in enabled_indicators:
            print("ğŸ“Š æ­£åœ¨è®¡ç®—å¸ƒæ—å¸¦(BOLL)æŒ‡æ ‡...")
            df = add_boll_indicators(df, **extra_params.get('boll_params', {}))
            calculated_indicators.append('BOLL')
        else:
            print("â­ï¸ å¸ƒæ—å¸¦æŒ‡æ ‡æœªå¯ç”¨ï¼Œè·³è¿‡è®¡ç®—")
            
        if 'cci' in enabled_indicators:
            print("ğŸ“Š æ­£åœ¨è®¡ç®—CCIæŒ‡æ ‡...")
            df = add_cci_indicators(df, **extra_params.get('cci_params', {}))
            calculated_indicators.append('CCI')
        else:
            print("â­ï¸ CCIæŒ‡æ ‡æœªå¯ç”¨ï¼Œè·³è¿‡è®¡ç®—")
            
        if 'wr' in enabled_indicators:
            print("ğŸ“Š æ­£åœ¨è®¡ç®—Williams %RæŒ‡æ ‡...")
            df = add_wr_indicators(df, **extra_params.get('wr_params', {}))
            calculated_indicators.append('WR')
        else:
            print("â­ï¸ Williams %RæŒ‡æ ‡æœªå¯ç”¨ï¼Œè·³è¿‡è®¡ç®—")
        
        print(f"âœ… æŒ‡æ ‡è®¡ç®—å®Œæˆï¼Œå·²è®¡ç®—: {calculated_indicators}")
        print(f"âš¡ æ€§èƒ½ä¼˜åŒ–ï¼šè·³è¿‡äº† {len(enabled_indicators) - len(calculated_indicators)} ä¸ªæœªå¯ç”¨çš„æŒ‡æ ‡")
        
        # ğŸ¯ é«˜çº§åˆ†æåŠŸèƒ½
        if enable_divergence and len(df) > 0:
            print("æ­£åœ¨è¿›è¡Œé«˜çº§æŠ€æœ¯åˆ†æ...")
            
            # ä¸ºæ¯ä¸ªè‚¡ç¥¨ä»£ç åˆ†åˆ«è¿›è¡Œåˆ†æ
            stock_analysis = {}
            unique_codes = df['code'].unique()
            
            for code in unique_codes[:10]:  # é™åˆ¶åˆ†ææ•°é‡ä»¥é¿å…æ€§èƒ½é—®é¢˜
                stock_data = df[df['code'] == code].copy()
                if len(stock_data) < 20:  # éœ€è¦è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œåˆ†æ
                    continue
                
                # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸæ’åº
                stock_data = stock_data.sort_values('date')
                
                # é‡æ–°è®¾ç½®ç´¢å¼•ä»¥ä¾¿æŒ‡æ ‡è®¡ç®—
                stock_data = stock_data.reset_index(drop=True)
                
                # åˆ›å»ºåˆ†æç»“æœå­—å…¸
                analysis_result = {
                    'code': code,
                    'data_points': len(stock_data)
                }
                
                # MACDèƒŒç¦»åˆ†æ
                if 'macd' in enabled_indicators:
                    try:
                        macd_analysis = analyze_macd_divergence(
                            stock_data, 
                            **macd_params
                        )
                        analysis_result['macd_divergence'] = macd_analysis
                    except Exception as e:
                        print(f"MACDèƒŒç¦»åˆ†æé”™è¯¯ ({code}): {e}")
                        analysis_result['macd_divergence'] = {'error': str(e)}
                
                # KDJèƒŒç¦»åˆ†æ
                if 'kdj' in enabled_indicators:
                    try:
                        kdj_analysis = analyze_kdj_divergence(
                            stock_data,
                            **kdj_params
                        )
                        analysis_result['kdj_divergence'] = kdj_analysis
                    except Exception as e:
                        print(f"KDJèƒŒç¦»åˆ†æé”™è¯¯ ({code}): {e}")
                        analysis_result['kdj_divergence'] = {'error': str(e)}
                
                # è¶‹åŠ¿ä¿¡å·åˆ†æ
                try:
                    trend_analysis = analyze_trend_signals(
                        stock_data,
                        **macd_params,
                        n=kdj_params.get('n', 9)
                    )
                    analysis_result['trend_signals'] = trend_analysis
                except Exception as e:
                    print(f"è¶‹åŠ¿ä¿¡å·åˆ†æé”™è¯¯ ({code}): {e}")
                    analysis_result['trend_signals'] = {'error': str(e)}
                
                stock_analysis[code] = analysis_result
            
            # å°†åˆ†æç»“æœé™„åŠ åˆ°DataFrameçš„é¢å¤–å±æ€§ä¸­
            if hasattr(df, 'attrs'):
                df.attrs['advanced_analysis'] = stock_analysis
            else:
                # å¦‚æœä¸æ”¯æŒattrsï¼Œåˆ›å»ºä¸€ä¸ªå…¨å±€å˜é‡å­˜å‚¨
                global _last_advanced_analysis
                _last_advanced_analysis = stock_analysis
            
            print(f"å®Œæˆ {len(stock_analysis)} åªè‚¡ç¥¨çš„é«˜çº§æŠ€æœ¯åˆ†æ")
        
        # åº”ç”¨ç­›é€‰æ¡ä»¶
        for indicator, condition in conditions.items():
            if indicator in df.columns:
                if callable(condition):
                    df = df[df[indicator].apply(condition)]
                else:
                    print(f"è­¦å‘Šï¼šæ¡ä»¶ {indicator} ä¸æ˜¯å¯è°ƒç”¨çš„å‡½æ•°")
        
        # é™åˆ¶ç»“æœæ•°é‡
        if limit and len(df) > limit:
            df = df.head(limit)
        
        # ğŸ”§ æ•°æ®æ¸…ç†ï¼šå¤„ç†NaN, inf, -infå€¼ï¼Œé¿å…JSONåºåˆ—åŒ–é”™è¯¯
        if len(df) > 0:
            # æ›¿æ¢NaNå€¼ä¸ºNone
            df = df.where(pd.notnull(df), None)
            
            # æ›¿æ¢æ— ç©·å¤§å€¼
            df = df.replace([float('inf'), float('-inf')], None)
            
            # ğŸ”§ å¤„ç†æ—¥æœŸåºåˆ—åŒ–ï¼šå°†Timestampè½¬æ¢ä¸ºå­—ç¬¦ä¸²
            if 'date' in df.columns:
                df['date'] = df['date'].dt.strftime('%Y-%m-%dT%H:%M:%S')
            
            # ç¡®ä¿æ•°å€¼åˆ—çš„æ•°æ®ç±»å‹æ­£ç¡®
            numeric_columns = df.select_dtypes(include=['number']).columns
            for col in numeric_columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        print(f"ä»æ•°æ®åº“ç­›é€‰å‡º {len(df)} æ¡è‚¡ç¥¨æ•°æ®")
        return df
        
    except Exception as e:
        print(f"ä»æ•°æ®åº“ç­›é€‰è‚¡ç¥¨æ—¶å‡ºé”™: {e}")
        print("å›é€€åˆ°CSVæ–‡ä»¶æ¨¡å¼")
        try:
            result = filter_stocks(indicator_names, conditions, '/home/liu/æ¡Œé¢/stock-main/backend/000001_10years.csv')
            if isinstance(result, pd.DataFrame):
                return result
            else:
                print(f"âŒ CSVå›é€€æ¨¡å¼è¿”å›éDataFrame: {type(result)}")
                return pd.DataFrame()
        except Exception as csv_e:
            print(f"âŒ CSVå›é€€æ¨¡å¼ä¹Ÿå¤±è´¥: {csv_e}")
            return pd.DataFrame()

def add_ma_indicators(df, ma_periods=[5, 10, 20]):
    """
    æ·»åŠ ç§»åŠ¨å¹³å‡çº¿æŒ‡æ ‡ - ä¼˜å…ˆä½¿ç”¨indicatorsæ¨¡å—ï¼Œå›é€€åˆ°ma_utils
    å‚æ•°:
        df: æ•°æ®æ¡†
        ma_periods: MAå‘¨æœŸåˆ—è¡¨ï¼Œé»˜è®¤[5, 10, 20]
    """
    try:
        df = df.copy()
        
        # ğŸ”§ ä¼˜å…ˆå°è¯•ä½¿ç”¨indicatorsæ¨¡å—çš„MAè®¡ç®—
        try:
            from indicators.ma import calculate as ma_calculate
            
            # å‡†å¤‡æ•°æ®æ ¼å¼
            data = df.rename(columns={
                'close': 'CLOSE',
                'high': 'HIGH',
                'low': 'LOW',
                'open': 'OPEN',
                'volume': 'VOLUME'
            })
            
            # æ ¹æ®ä¼ å…¥çš„å‘¨æœŸè®¡ç®—MA
            for period in ma_periods:
                ma_values = ma_calculate(data, N=period)
                df[f'ma{period}'] = ma_values
                print(f"âœ… ä½¿ç”¨indicatorsæ¨¡å—è®¡ç®—MA{period}")
                
        except ImportError as e:
            print(f"âš ï¸ indicatorsæ¨¡å—ä¸å¯ç”¨ï¼Œå›é€€åˆ°ma_utils: {e}")
            # å›é€€åˆ°ma_utilså®ç°
            from ma_utils import calculate_ma
            
            for period in ma_periods:
                df[f'ma{period}'] = calculate_ma(df['close'], period)
                print(f"âœ… ä½¿ç”¨ma_utilsè®¡ç®—MA{period}")
        
        # ä¿æŒå‘åå…¼å®¹æ€§ï¼Œç¡®ä¿åŸºç¡€å­—æ®µå­˜åœ¨
        if 5 in ma_periods:
            df['ma5'] = df['ma5'] if 'ma5' in df.columns else calculate_ma(df['close'], 5)
        if 10 in ma_periods:
            df['ma10'] = df['ma10'] if 'ma10' in df.columns else calculate_ma(df['close'], 10)
        if 20 in ma_periods:
            df['ma20'] = df['ma20'] if 'ma20' in df.columns else calculate_ma(df['close'], 20)
            df['ma'] = df['ma20']  # é»˜è®¤ä½¿ç”¨20æ—¥å‡çº¿
        
        return df
    except Exception as e:
        print(f"âŒ è®¡ç®—MAæŒ‡æ ‡æ—¶å‡ºé”™: {e}")
        return df

def add_macd_indicators(df, short=12, long=26, signal=9):
    """
    æ·»åŠ MACDæŒ‡æ ‡ - ä½¿ç”¨indicatorsæ¨¡å—çš„å®ç°
    å‚æ•°:
        df: æ•°æ®æ¡†
        short: çŸ­å‘¨æœŸEMAï¼Œé»˜è®¤12
        long: é•¿å‘¨æœŸEMAï¼Œé»˜è®¤26  
        signal: ä¿¡å·çº¿å‘¨æœŸï¼Œé»˜è®¤9
    """
    try:
        from indicators.macd import calculate
        df = df.copy()
        # é‡å‘½ååˆ—ä»¥åŒ¹é…indicatorsæ¨¡å—çš„æœŸæœ›æ ¼å¼
        data = df.rename(columns={
            'close': 'CLOSE',
            'high': 'HIGH',
            'low': 'LOW',
            'open': 'OPEN',
            'volume': 'VOLUME'
        })
        # è°ƒç”¨indicatorsæ¨¡å—çš„MACDè®¡ç®—
        dif, dea, macd = calculate(data, short=short, long=long, signal=signal)
        df['macd'] = macd          # MACDæŸ±çŠ¶å›¾
        df['macd_signal'] = dea    # ä¿¡å·çº¿(DEA)
        df['macd_histogram'] = dif # DIFçº¿
        print(f"âœ… ä½¿ç”¨indicatorsæ¨¡å—è®¡ç®—MACD({short},{long},{signal})")
        return df
    except Exception as e:
        print(f"âŒ è®¡ç®—MACDæŒ‡æ ‡æ—¶å‡ºé”™: {e}")
        return df

def add_kdj_indicators(df, n=9, k_factor=2/3, d_factor=2/3):
    """
    æ·»åŠ KDJæŒ‡æ ‡ - ä¼˜å…ˆä½¿ç”¨indicatorsæ¨¡å—ï¼Œå›é€€åˆ°indicator_utils
    å‚æ•°:
        df: æ•°æ®æ¡†
        n: RSVè®¡ç®—å‘¨æœŸï¼Œé»˜è®¤9
        k_factor: Kå€¼å¹³æ»‘å› å­ï¼Œé»˜è®¤2/3
        d_factor: Då€¼å¹³æ»‘å› å­ï¼Œé»˜è®¤2/3
    """
    try:
        df = df.copy()
        
        # ğŸ”§ ä¼˜å…ˆå°è¯•ä½¿ç”¨indicatorsæ¨¡å—çš„KDJè®¡ç®—
        try:
            from indicators.kdj import kdj
            
            # å‡†å¤‡æ•°æ®æ ¼å¼
            data = df.rename(columns={
                'close': 'CLOSE',
                'high': 'HIGH',
                'low': 'LOW',
                'open': 'OPEN',
                'volume': 'VOLUME'
            })
            
            # è°ƒç”¨indicatorsæ¨¡å—çš„KDJè®¡ç®—
            k_val, d_val, j_val = kdj(data, n=n)
            df['kdj_k'] = k_val
            df['kdj_d'] = d_val  
            df['kdj_j'] = j_val
            print(f"âœ… ä½¿ç”¨indicatorsæ¨¡å—è®¡ç®—KDJ({n})")
            
        except ImportError as e:
            print(f"âš ï¸ indicators.kdjä¸å¯ç”¨ï¼Œå›é€€åˆ°indicator_utils: {e}")
            # å›é€€åˆ°indicator_utilså®ç°
            from indicator_utils import calculate_kdj
            kdj_data = calculate_kdj(df['high'], df['low'], df['close'], n=n)
            df['kdj_k'] = kdj_data['k']
            df['kdj_d'] = kdj_data['d']
            df['kdj_j'] = kdj_data['j']
            print(f"âœ… ä½¿ç”¨indicator_utilsè®¡ç®—KDJ({n})")
            
        return df
    except Exception as e:
        print(f"âŒ è®¡ç®—KDJæŒ‡æ ‡æ—¶å‡ºé”™: {e}")
        return df

def add_rsi_indicators(df, period=14):
    """
    æ·»åŠ RSIæŒ‡æ ‡ - ä½¿ç”¨indicatorsæ¨¡å—çš„å®ç°
    å‚æ•°:
        df: æ•°æ®æ¡†
        period: RSIè®¡ç®—å‘¨æœŸï¼Œé»˜è®¤14
    """
    try:
        from indicators.rsi import calculate
        df = df.copy()
        # é‡å‘½ååˆ—ä»¥åŒ¹é…indicatorsæ¨¡å—çš„æœŸæœ›æ ¼å¼
        data = df.rename(columns={
            'close': 'CLOSE',
            'high': 'HIGH',
            'low': 'LOW',
            'open': 'OPEN',
            'volume': 'VOLUME'
        })
        # è°ƒç”¨indicatorsæ¨¡å—çš„RSIè®¡ç®—
        rsi_values = calculate(data, N=period)
        df['rsi'] = rsi_values
        return df
    except Exception as e:
        print(f"è®¡ç®—RSIæŒ‡æ ‡æ—¶å‡ºé”™: {e}")
        return df

def add_boll_indicators(df, period=20, std_dev=2):
    """
    æ·»åŠ å¸ƒæ—å¸¦(BOLL)æŒ‡æ ‡ - ä½¿ç”¨indicatorsæ¨¡å—çš„å®ç°
    å‚æ•°:
        df: æ•°æ®æ¡†
        period: ç§»åŠ¨å¹³å‡å‘¨æœŸï¼Œé»˜è®¤20
        std_dev: æ ‡å‡†å·®å€æ•°ï¼Œé»˜è®¤2
    """
    try:
        from indicators.boll import calculate
        df = df.copy()
        # é‡å‘½ååˆ—ä»¥åŒ¹é…indicatorsæ¨¡å—çš„æœŸæœ›æ ¼å¼
        data = df.rename(columns={
            'close': 'CLOSE',
            'high': 'HIGH',
            'low': 'LOW',
            'open': 'OPEN',
            'volume': 'VOLUME'
        })
        
        # indicators/boll.pyåªè¿”å›ä¸­è½¨ï¼Œæˆ‘ä»¬éœ€è¦å®Œæ•´çš„å¸ƒæ—å¸¦
        # è®©æˆ‘ä»¬è‡ªå·±è®¡ç®—å®Œæ•´çš„å¸ƒæ—å¸¦ï¼Œä½†åŸºäºindicatorsæ¨¡å—çš„é€»è¾‘
        close = data['CLOSE']
        mid = close.rolling(window=period, min_periods=1).mean()
        std = close.rolling(window=period, min_periods=1).std()
        upper = mid + std_dev * std
        lower = mid - std_dev * std
        
        df['boll_mid'] = mid      # ä¸­è½¨ï¼ˆç§»åŠ¨å¹³å‡çº¿ï¼‰
        df['boll_upper'] = upper  # ä¸Šè½¨
        df['boll_lower'] = lower  # ä¸‹è½¨
        df['boll'] = mid         # å…¼å®¹æ€§å­—æ®µï¼Œé»˜è®¤ä½¿ç”¨ä¸­è½¨
        
        return df
    except Exception as e:
        print(f"è®¡ç®—BOLLæŒ‡æ ‡æ—¶å‡ºé”™: {e}")
        return df

def add_cci_indicators(df, period=14):
    """
    æ·»åŠ CCIæŒ‡æ ‡ - ä½¿ç”¨indicatorsæ¨¡å—çš„å®ç°
    å‚æ•°:
        df: æ•°æ®æ¡†
        period: CCIè®¡ç®—å‘¨æœŸï¼Œé»˜è®¤14
    """
    try:
        from indicators.cci import calculate
        df = df.copy()
        # é‡å‘½ååˆ—ä»¥åŒ¹é…indicatorsæ¨¡å—çš„æœŸæœ›æ ¼å¼
        data = df.rename(columns={
            'close': 'CLOSE',
            'high': 'HIGH',
            'low': 'LOW',
            'open': 'OPEN',
            'volume': 'VOLUME'
        })
        # è°ƒç”¨indicatorsæ¨¡å—çš„CCIè®¡ç®—
        cci_values = calculate(data, N=period)
        df['cci'] = cci_values
        print(f"âœ… ä½¿ç”¨indicatorsæ¨¡å—è®¡ç®—CCI({period})")
        return df
    except Exception as e:
        print(f"âŒ è®¡ç®—CCIæŒ‡æ ‡æ—¶å‡ºé”™: {e}")
        return df

def add_wr_indicators(df, period=14):
    """
    æ·»åŠ Williams %RæŒ‡æ ‡ - ä½¿ç”¨indicatorsæ¨¡å—çš„å®ç°
    å‚æ•°:
        df: æ•°æ®æ¡†
        period: WRè®¡ç®—å‘¨æœŸï¼Œé»˜è®¤14
    """
    try:
        from indicators.wr import calculate
        df = df.copy()
        # é‡å‘½ååˆ—ä»¥åŒ¹é…indicatorsæ¨¡å—çš„æœŸæœ›æ ¼å¼
        data = df.rename(columns={
            'close': 'CLOSE',
            'high': 'HIGH',
            'low': 'LOW',
            'open': 'OPEN',
            'volume': 'VOLUME'
        })
        # è°ƒç”¨indicatorsæ¨¡å—çš„WRè®¡ç®—
        wr_values = calculate(data)
        df['wr'] = wr_values
        print(f"âœ… ä½¿ç”¨indicatorsæ¨¡å—è®¡ç®—Williams %R({period})")
        return df
    except Exception as e:
        print(f"âŒ è®¡ç®—Williams %RæŒ‡æ ‡æ—¶å‡ºé”™: {e}")
        return df

def compress_stock_results(df, compress_mode='latest'):
    """
    å‹ç¼©ç­›é€‰ç»“æœ - å°†åŒä¸€åªè‚¡ç¥¨çš„å¤šæ¡è®°å½•åˆå¹¶ä¸ºä¸€æ¡
    
    Args:
        df: ç­›é€‰ç»“æœDataFrame
        compress_mode: å‹ç¼©æ¨¡å¼
            - 'latest': ä¿ç•™æ¯åªè‚¡ç¥¨çš„æœ€æ–°æ—¥æœŸè®°å½•
            - 'best': ä¿ç•™æ¯åªè‚¡ç¥¨è¡¨ç°æœ€å¥½çš„è®°å½•
            - 'summary': ç”Ÿæˆæ¯åªè‚¡ç¥¨çš„æ±‡æ€»ç»Ÿè®¡
    
    Returns:
        å‹ç¼©åçš„DataFrame
    """
    if len(df) == 0:
        return df
    
    print(f"ğŸ”„ å¼€å§‹å‹ç¼©ç­›é€‰ç»“æœ - æ¨¡å¼: {compress_mode}")
    original_count = len(df)
    unique_stocks = df['code'].nunique() if 'code' in df.columns else 0
    
    print(f"   å‹ç¼©å‰: {original_count} æ¡è®°å½•ï¼Œæ¥è‡ª {unique_stocks} åªè‚¡ç¥¨")
    
    if 'code' not in df.columns:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°è‚¡ç¥¨ä»£ç åˆ—ï¼Œè·³è¿‡å‹ç¼©")
        return df
    
    compressed_results = []
    
    for stock_code, group in df.groupby('code'):
        if compress_mode == 'latest':
            # ä¿ç•™æœ€æ–°æ—¥æœŸçš„è®°å½•
            if 'date' in group.columns:
                group = group.sort_values('date', ascending=False)
                latest_record = group.iloc[0].copy()
                
                # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                latest_record['data_points_count'] = len(group)
                latest_record['date_range_start'] = group['date'].min()
                latest_record['date_range_end'] = group['date'].max()
                
                # å¦‚æœæœ‰ä»·æ ¼æ•°æ®ï¼Œè®¡ç®—åŒºé—´å†…çš„ç»Ÿè®¡
                if 'close' in group.columns:
                    latest_record['period_high'] = group['close'].max()
                    latest_record['period_low'] = group['close'].min()
                    latest_record['period_change_pct'] = ((group['close'].iloc[0] - group['close'].iloc[-1]) / group['close'].iloc[-1] * 100) if len(group) > 1 else 0
                
                compressed_results.append(latest_record)
                
        elif compress_mode == 'best':
            # ä¿ç•™è¡¨ç°æœ€å¥½çš„è®°å½•ï¼ˆåŸºäºæ”¶ç›˜ä»·æœ€é«˜ï¼‰
            if 'close' in group.columns:
                best_record = group.loc[group['close'].idxmax()].copy()
                
                # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                best_record['data_points_count'] = len(group)
                best_record['date_range_start'] = group['date'].min()
                best_record['date_range_end'] = group['date'].max()
                best_record['period_high'] = group['close'].max()
                best_record['period_low'] = group['close'].min()
                
                compressed_results.append(best_record)
            else:
                # å¦‚æœæ²¡æœ‰ä»·æ ¼æ•°æ®ï¼Œä½¿ç”¨æœ€æ–°è®°å½•
                latest_record = group.iloc[0].copy()
                latest_record['data_points_count'] = len(group)
                compressed_results.append(latest_record)
                
        elif compress_mode == 'summary':
            # ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡è®°å½•
            summary_record = {}
            
            # åŸºæœ¬ä¿¡æ¯
            summary_record['code'] = stock_code
            summary_record['name'] = group['name'].iloc[0] if 'name' in group.columns else stock_code
            summary_record['data_points_count'] = len(group)
            
            # æ—¶é—´ä¿¡æ¯
            if 'date' in group.columns:
                summary_record['date_range_start'] = group['date'].min()
                summary_record['date_range_end'] = group['date'].max()
                summary_record['date'] = group['date'].max()  # ä½¿ç”¨æœ€æ–°æ—¥æœŸä½œä¸ºä»£è¡¨æ—¥æœŸ
            
            # ä»·æ ¼ç»Ÿè®¡
            if 'close' in group.columns:
                summary_record['close'] = group['close'].iloc[0]  # æœ€æ–°æ”¶ç›˜ä»·
                summary_record['period_high'] = group['close'].max()
                summary_record['period_low'] = group['close'].min()
                summary_record['period_avg'] = group['close'].mean()
                summary_record['period_change_pct'] = ((group['close'].iloc[0] - group['close'].iloc[-1]) / group['close'].iloc[-1] * 100) if len(group) > 1 else 0
            
            # æŒ‡æ ‡ç»Ÿè®¡ï¼ˆå–æœ€æ–°å€¼ï¼‰
            indicator_columns = ['ma5', 'ma10', 'ma20', 'ma60', 'macd', 'macd_signal', 'macd_histogram', 
                               'kdj_k', 'kdj_d', 'kdj_j', 'rsi', 'boll_upper', 'boll_mid', 'boll_lower']
            
            for col in indicator_columns:
                if col in group.columns:
                    latest_value = group[col].iloc[0]
                    if pd.notna(latest_value):
                        summary_record[col] = latest_value
                        # æ·»åŠ æŒ‡æ ‡çš„åŒºé—´ç»Ÿè®¡
                        summary_record[f'{col}_max'] = group[col].max()
                        summary_record[f'{col}_min'] = group[col].min()
                        summary_record[f'{col}_avg'] = group[col].mean()
            
            compressed_results.append(pd.Series(summary_record))
    
    # è½¬æ¢ä¸ºDataFrame
    if compressed_results:
        if compress_mode == 'summary':
            compressed_df = pd.DataFrame(compressed_results)
        else:
            compressed_df = pd.DataFrame(compressed_results)
        
        # é‡ç½®ç´¢å¼•
        compressed_df = compressed_df.reset_index(drop=True)
        
        print(f"   å‹ç¼©å: {len(compressed_df)} æ¡è®°å½•ï¼Œæ¯åªè‚¡ç¥¨ä¸€æ¡")
        print(f"   å‹ç¼©æ¯”: {len(compressed_df)}/{original_count} = {len(compressed_df)/original_count*100:.1f}%")
        
        return compressed_df
    else:
        print("âš ï¸ å‹ç¼©åæ²¡æœ‰ç»“æœ")
        return pd.DataFrame()


@csrf_exempt
def filter_stocks_api(request):
    if request.method == 'POST':
        try:
            data = json.loads(request.body.decode('utf-8'))
            indicator_names = data.get('indicators', [])
            conditions_dict = data.get('conditions', {})
            
            # æ–°å¢ï¼šè·å–å¯ç”¨çš„æŒ‡æ ‡åˆ—è¡¨å’Œå‘¨æœŸå‚æ•°
            enabled_indicators = data.get('enabled_indicators', indicator_names)  # å¯ç”¨çš„æŒ‡æ ‡
            period = data.get('period', 'æ—¥')  # å‘¨æœŸï¼šæ—¥/å‘¨/æœˆ/å¹´
            custom_capital = data.get('custom_capital', 100000)  # è‡ªå®šä¹‰èµ„é‡‘é‡
            
            # ğŸ†• æ–°å¢ï¼šæ•°æ®é¢‘ç‡å‚æ•°
            data_frequency = data.get('data_frequency', 'daily')  # æ•°æ®é¢‘ç‡ï¼šdaily/minute/tick
            minute_interval = data.get('minute_interval', '5')    # åˆ†é’Ÿå‘¨æœŸï¼š1/5/15/30/60
            initial_capital = data.get('initial_capital', custom_capital)  # åˆå§‹èµ„é‡‘ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰
            
            # ğŸ†• æ–°å¢ï¼šç»“æœå‹ç¼©å‚æ•°
            compress_results = data.get('compress_results', True)  # æ˜¯å¦å‹ç¼©ç»“æœ
            compress_mode = data.get('compress_mode', 'latest')    # å‹ç¼©æ¨¡å¼ï¼šlatest/best/summary
            
            # ğŸ†• è·å–æŒ‡æ ‡è‡ªå®šä¹‰å‚æ•°
            macd_params = data.get('macd_params', {})  # MACDå‚æ•°
            kdj_params = data.get('kdj_params', {})    # KDJå‚æ•°  
            ma_params = data.get('ma_params', {})      # MAå‚æ•°
            rsi_params = data.get('rsi_params', {})    # RSIå‚æ•°
            boll_params = data.get('boll_params', {})  # BOLLå‚æ•°
            cci_params = data.get('cci_params', {})    # CCIå‚æ•°
            wr_params = data.get('wr_params', {})      # Williams %Rå‚æ•°
            
            # ğŸ”§ å¸‚åœºç­›é€‰å‚æ•° - é‡è¦ä¿®å¤ï¼šæ·»åŠ ç¼ºå¤±çš„å¸‚åœºç­›é€‰
            market_filter = data.get('market', 'ALL')  # å¸‚åœºç­›é€‰ï¼šshanghai/shenzhen/ALL
            enable_divergence = data.get('enable_divergence', True)  # æ˜¯å¦å¯ç”¨èƒŒç¦»åˆ†æ
            
            # ğŸ†• æ–°å¢ï¼šè‚¡ç¥¨ç»“æœå‹ç¼©å‚æ•°
            compress_by_stock = data.get('compress_by_stock', False)  # æ˜¯å¦æŒ‰è‚¡ç¥¨å‹ç¼©ç»“æœ
            
            # ğŸ“Š æ™ºèƒ½æŒ‡æ ‡éªŒè¯ï¼šç¡®ä¿åªå¤„ç†æœ‰æ•ˆçš„å¯ç”¨æŒ‡æ ‡
            SUPPORTED_INDICATORS = ['ma', 'macd', 'kdj', 'rsi', 'boll', 'cci', 'wr']
            validated_indicators = [ind for ind in enabled_indicators if ind in SUPPORTED_INDICATORS]
            skipped_indicators = [ind for ind in enabled_indicators if ind not in SUPPORTED_INDICATORS]
            
            if skipped_indicators:
                print(f"âš ï¸ è·³è¿‡ä¸æ”¯æŒçš„æŒ‡æ ‡: {skipped_indicators}")
            
            print(f"âœ… éªŒè¯é€šè¿‡çš„å¯ç”¨æŒ‡æ ‡: {validated_indicators}")
            print(f"ğŸ“Š æ•°æ®å‘¨æœŸ: {period}")
            print(f"ğŸ’° è‡ªå®šä¹‰èµ„é‡‘é‡: {custom_capital}")
            print(f"ğŸ’° åˆå§‹èµ„é‡‘: {initial_capital}")
            print(f"â±ï¸ æ•°æ®é¢‘ç‡: {data_frequency}")
            print(f"ğŸ“ˆ åˆ†é’Ÿå‘¨æœŸ: {minute_interval}")
            print(f"ğŸª å¸‚åœºç­›é€‰: {market_filter}")
            print(f"ğŸ” å¯ç”¨èƒŒç¦»åˆ†æ: {enable_divergence}")
            print(f"ğŸ”„ ç»“æœå‹ç¼©: {compress_results} (æ¨¡å¼: {compress_mode})")
            if macd_params:
                print(f"MACDè‡ªå®šä¹‰å‚æ•°: {macd_params}")
            if kdj_params:
                print(f"KDJè‡ªå®šä¹‰å‚æ•°: {kdj_params}")
            if ma_params:
                print(f"MAè‡ªå®šä¹‰å‚æ•°: {ma_params}")
            
            # æ”¯æŒè¡¨è¾¾å¼å­—ç¬¦ä¸²è½¬ lambda
            conditions = {}
            for k, v in conditions_dict.items():
                # æ”¯æŒ op/value æ ¼å¼ï¼Œè‡ªåŠ¨è°ƒç”¨ compare.py
                if isinstance(v, dict) and 'op' in v and 'value' in v:
                    op = v['op']
                    val = v['value']
                    if op == '>':
                        conditions[k] = lambda x, val=val: compare.greater(x, val)
                    elif op == '<':
                        conditions[k] = lambda x, val=val: compare.less(x, val)
                    elif op == '>=':
                        conditions[k] = lambda x, val=val: compare.greater_equal(x, val)
                    elif op == '<=':
                        conditions[k] = lambda x, val=val: compare.less_equal(x, val)
                    elif op == '=':
                        conditions[k] = lambda x, val=val: compare.equal(x, val)
                    else:
                        conditions[k] = lambda x: True
                elif isinstance(v, str):
                    conditions[k] = eval(f'lambda x: {v}')
                else:
                    conditions[k] = v
            
            # è·å–æ—¥æœŸèŒƒå›´
            start_date = data.get('start_date')
            end_date = data.get('end_date')
            
            # æ„å»ºextraå‚æ•°ï¼Œä¼ é€’å¯ç”¨æŒ‡æ ‡å’Œå‘¨æœŸä¿¡æ¯
            extra_params = {
                'enabled_indicators': validated_indicators,  # ğŸ”§ ä½¿ç”¨éªŒè¯åçš„æŒ‡æ ‡åˆ—è¡¨
                'period': period,
                'custom_capital': custom_capital,
                'initial_capital': initial_capital,  # ğŸ†• æ·»åŠ åˆå§‹èµ„é‡‘å‚æ•°
                'data_frequency': data_frequency,     # ğŸ†• æ·»åŠ æ•°æ®é¢‘ç‡å‚æ•°
                'minute_interval': minute_interval,   # ğŸ†• æ·»åŠ åˆ†é’Ÿå‘¨æœŸå‚æ•°
                'start_date': start_date,
                'end_date': end_date,
                'macd_params': macd_params,
                'kdj_params': kdj_params,
                'ma_params': ma_params,
                'rsi_params': rsi_params,             # ğŸ†• æ·»åŠ RSIå‚æ•°
                'boll_params': boll_params,           # ğŸ†• æ·»åŠ BOLLå‚æ•°
                'cci_params': cci_params,             # ğŸ†• æ·»åŠ CCIå‚æ•°
                'wr_params': wr_params,               # ğŸ†• æ·»åŠ Williams %Rå‚æ•°
                'market': market_filter,  # ğŸ”§ é‡è¦ä¿®å¤ï¼šæ·»åŠ å¸‚åœºç­›é€‰å‚æ•°
                'enable_divergence': enable_divergence,  # ğŸ”§ æ·»åŠ èƒŒç¦»åˆ†æå‚æ•°
                'compress_results': compress_results,     # ğŸ†• æ·»åŠ ç»“æœå‹ç¼©å‚æ•°
                'compress_mode': compress_mode            # ğŸ†• æ·»åŠ å‹ç¼©æ¨¡å¼å‚æ•°
            }
            
            print(f"ğŸ“‹ ä¼ é€’ç»™ç­›é€‰å‡½æ•°çš„å‚æ•°:")
            print(f"   - å¯ç”¨æŒ‡æ ‡: {validated_indicators}")
            print(f"   - ç­›é€‰æ¡ä»¶æ•°é‡: {len(conditions)}")
            print(f"   - æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
            print(f"   - è‡ªå®šä¹‰å‚æ•°: MACD={bool(macd_params)}, KDJ={bool(kdj_params)}, MA={bool(ma_params)}")
            
            # ä½¿ç”¨æ•°æ®åº“æ¨¡å¼è¿›è¡Œç­›é€‰
            result_df = filter_stocks_from_database(
                validated_indicators,  # ğŸ”§ ä½¿ç”¨éªŒè¯åçš„æŒ‡æ ‡åˆ—è¡¨
                conditions, 
                start_date=start_date,
                end_date=end_date,
                limit=100,
                extra_params=extra_params
            )
            
            # ğŸ”§ é‡è¦ï¼šç¡®ä¿result_dfæ˜¯DataFrameç±»å‹
            if not isinstance(result_df, pd.DataFrame):
                print(f"âŒ ç­›é€‰ç»“æœç±»å‹é”™è¯¯: {type(result_df)}, å†…å®¹: {result_df}")
                return JsonResponse({
                    'success': False, 
                    'error': f'ç­›é€‰ç»“æœç±»å‹é”™è¯¯: {type(result_df).__name__}',
                    'details': str(result_df) if len(str(result_df)) < 200 else str(result_df)[:200] + '...'
                })
            
            # ğŸ†• è‚¡ç¥¨ç»“æœå‹ç¼©å¤„ç†
            original_count = len(result_df)
            original_unique_stocks = result_df['code'].nunique() if len(result_df) > 0 and 'code' in result_df.columns else 0
            compression_stats = None
            
            # ä½¿ç”¨æ–°çš„compress_by_stockå‚æ•°è¿›è¡Œå‹ç¼©
            if compress_by_stock and len(result_df) > 0:
                try:
                    compressed_df, compression_stats = compress_stock_results(result_df, compress_by_stock=True)
                    result_df = compressed_df
                    
                    print(f"ğŸ“Š è‚¡ç¥¨å‹ç¼©å®Œæˆï¼š{original_count} æ¡è®°å½• â†’ {len(result_df)} åªè‚¡ç¥¨")
                    if isinstance(compression_stats, dict):
                        print(f"å‹ç¼©æ¯”ç‡ï¼š{compression_stats.get('compression_ratio', 0):.1%}")
                    else:
                        print(f"å‹ç¼©ç»Ÿè®¡ä¿¡æ¯ç±»å‹å¼‚å¸¸: {type(compression_stats)}")
                    
                except Exception as e:
                    print(f"âŒ è‚¡ç¥¨å‹ç¼©å¤±è´¥ï¼š{e}")
                    import traceback
                    traceback.print_exc()
                    # å‹ç¼©å¤±è´¥æ—¶ä¿æŒåŸå§‹ç»“æœ
            
            
            # æ¸…ç†æ•°æ®ä¸­çš„NaNå€¼ï¼Œç¡®ä¿JSONåºåˆ—åŒ–æ­£ç¡®
            import numpy as np
            result_df = result_df.replace([np.nan, np.inf, -np.inf], None)
            
            # ğŸ“Š è®¡ç®—æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
            performance_stats = {
                'total_indicators_requested': len(enabled_indicators),
                'valid_indicators_processed': len(validated_indicators),
                'skipped_indicators': len(enabled_indicators) - len(validated_indicators),
                'data_rows_processed': original_count,
                'compressed_rows_returned': len(result_df),
                'unique_stocks_found': original_unique_stocks,
                'compression_ratio': len(result_df) / original_count if original_count > 0 else 0,
                'time_range_days': (pd.to_datetime(end_date) - pd.to_datetime(start_date)).days if start_date and end_date else 0,
                'compress_enabled': compress_by_stock,  # æ›´æ–°ä¸ºcompress_by_stock
                'compress_mode': compress_mode,
                'compression_stats': compression_stats  # æ·»åŠ è¯¦ç»†å‹ç¼©ç»Ÿè®¡
            }
            
            # è¿”å› jsonï¼ŒåŒ…å«å‘¨æœŸå’Œèµ„é‡‘ä¿¡æ¯ä»¥åŠæ€§èƒ½ç»Ÿè®¡
            return JsonResponse({
                'success': True, 
                'data': result_df.to_dict(orient='records'),
                'count': len(result_df),
                'original_count': original_count,  # ğŸ†• æ·»åŠ åŸå§‹æ•°æ®é‡
                'unique_stocks': original_unique_stocks,  # ğŸ†• æ·»åŠ å”¯ä¸€è‚¡ç¥¨æ•°é‡
                'period': period,
                'custom_capital': custom_capital,
                'initial_capital': initial_capital,     # ğŸ†• æ·»åŠ åˆå§‹èµ„é‡‘åˆ°å“åº”
                'data_frequency': data_frequency,       # ğŸ†• æ·»åŠ æ•°æ®é¢‘ç‡åˆ°å“åº”
                'minute_interval': minute_interval,     # ğŸ†• æ·»åŠ åˆ†é’Ÿå‘¨æœŸåˆ°å“åº”
                'enabled_indicators': validated_indicators,  # ğŸ”§ è¿”å›éªŒè¯åçš„æŒ‡æ ‡åˆ—è¡¨
                'performance_stats': performance_stats,      # ğŸ†• æ·»åŠ æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
                'skipped_indicators': skipped_indicators,    # ğŸ†• è¿”å›è·³è¿‡çš„æŒ‡æ ‡
                'compression_info': {                        # ğŸ†• æ·»åŠ å‹ç¼©ä¿¡æ¯
                    'enabled': compress_results,
                    'mode': compress_mode,
                    'original_records': original_count,
                    'compressed_records': len(result_df),
                    'compression_ratio': f"{len(result_df) / original_count * 100:.1f}%" if original_count > 0 else "0%"
                }
            })
        except Exception as e:
            return JsonResponse({'success': False, 'error': str(e)})
    else:
        return JsonResponse({'success': False, 'error': 'Only POST allowed'})

    
    # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„å¤„ç†
    for stock_code, group_df in df.groupby('code'):
        try:
            stock_df = group_df.copy().reset_index(drop=True)
            
            # ä¸ºæ¯ä¸ªæŒ‡æ ‡è®¡ç®—å€¼
            for indicator_name in indicator_names:
                indicator_values = calculate_indicator(stock_df, indicator_name)
                if indicator_values is not None:
                    stock_df[indicator_name] = indicator_values
            
            # åº”ç”¨ç­›é€‰æ¡ä»¶
            meets_conditions = True
            for condition_name, condition_func in conditions.items():
                if condition_name in stock_df.columns:
                    try:
                        # å–æœ€æ–°çš„æŒ‡æ ‡å€¼è¿›è¡Œåˆ¤æ–­
                        latest_value = stock_df[condition_name].iloc[-1]
                        if pd.notna(latest_value) and not condition_func(latest_value):
                            meets_conditions = False
                            break
                    except Exception as e:
                        print(f"âš ï¸ æ¡ä»¶æ£€æŸ¥å¤±è´¥ {condition_name}: {e}")
                        meets_conditions = False
                        break
            
            # å¦‚æœæ»¡è¶³æ‰€æœ‰æ¡ä»¶ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
            if meets_conditions:
                filtered_results.append(stock_df)
                
        except Exception as e:
            print(f"âš ï¸ å¤„ç†è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}")
            continue
    
    # åˆå¹¶æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨æ•°æ®
    if filtered_results:
        final_df = pd.concat(filtered_results, ignore_index=True)
        return final_df
    else:
        return pd.DataFrame()

def calculate_indicator(df, indicator_name):
    """
    è®¡ç®—å•ä¸ªæŠ€æœ¯æŒ‡æ ‡
    """
    try:
        if indicator_name == 'ma':
            # ç®€å•ç§»åŠ¨å¹³å‡çº¿
            if 'CLOSE' in df.columns:
                return df['CLOSE'].rolling(window=20, min_periods=1).mean()
            
        elif indicator_name == 'macd':
            # MACDæŒ‡æ ‡ - ç®€åŒ–ç‰ˆæœ¬
            if 'CLOSE' in df.columns:
                exp1 = df['CLOSE'].ewm(span=12).mean()
                exp2 = df['CLOSE'].ewm(span=26).mean()
                macd_line = exp1 - exp2
                return macd_line
                
        elif indicator_name == 'kdj':
            # KDJæŒ‡æ ‡ - ç®€åŒ–ç‰ˆæœ¬
            if all(col in df.columns for col in ['HIGH', 'LOW', 'CLOSE']):
                low_min = df['LOW'].rolling(window=9).min()
                high_max = df['HIGH'].rolling(window=9).max()
                rsv = (df['CLOSE'] - low_min) / (high_max - low_min) * 100
                k = rsv.ewm(alpha=1/3).mean()
                return k
                
        elif indicator_name == 'pe':
            # å¸‚ç›ˆç‡ç›´æ¥è¿”å›
            if 'PE' in df.columns:
                return df['PE']
                
        elif indicator_name == 'pb':
            # å¸‚å‡€ç‡ç›´æ¥è¿”å›
            if 'PB' in df.columns:
                return df['PB']
        
        # å¦‚æœæŒ‡æ ‡ä¸æ”¯æŒï¼Œè¿”å›None
        return None
        
    except Exception as e:
        print(f"âš ï¸ è®¡ç®—æŒ‡æ ‡ {indicator_name} æ—¶å‡ºé”™: {e}")
        return None
# ä¿®å¤æŒ‡æ ‡å¯¼å…¥ - ç›´æ¥ä»indicatorsæ¨¡å—å¯¼å…¥
try:
    from indicators import ma, dif, dea, macd, kdj
except ImportError:
    # å¦‚æœç›´æ¥å¯¼å…¥å¤±è´¥ï¼Œå°è¯•å•ç‹¬å¯¼å…¥
    import indicators.ma as ma
    import indicators.dif as dif
    import indicators.dea as dea  
    import indicators.macd as macd
    import indicators.kdj as kdj


def get_mysql_df(host, user, password, database, table, charset='utf8mb4'):
    engine = create_engine(f"mysql+pymysql://{user}:{password}@{host}/{database}?charset={charset}")
    sql = f"SELECT * FROM {table}"
    print('SQL:', sql)
    df = pd.read_sql(sql, engine)
    return df

def get_csv_df(csv_path):
    print(f'Reading CSV: {csv_path}')
    df = pd.read_csv(csv_path)
    return df

def get_indicator(indicator, df, extra):
    """
    ğŸ¯ æ™ºèƒ½æŒ‡æ ‡è®¡ç®—å‡½æ•° - æ ¹æ®å‰ç«¯å¯ç”¨çŠ¶æ€è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    åªæœ‰åœ¨å‰ç«¯å¯ç”¨çš„æŒ‡æ ‡æ‰ä¼šè¢«è®¡ç®—ï¼Œé¿å…ä¸å¿…è¦çš„è®¡ç®—å¼€é”€
    
    å‚æ•°:
        indicator: æŒ‡æ ‡åç§°
        df: æ•°æ®æ¡†
        extra: é¢å¤–å‚æ•°ï¼ŒåŒ…å«enabled_indicatorsç­‰
    
    è¿”å›:
        è®¡ç®—ç»“æœæˆ–Noneï¼ˆå¦‚æœæŒ‡æ ‡æœªå¯ç”¨ï¼‰
    """
    # ğŸ“‹ æ£€æŸ¥æŒ‡æ ‡æ˜¯å¦è¢«å¯ç”¨
    enabled_indicators = extra.get('enabled_indicators', [])
    
    # ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šç‰¹æ®Šå‚æ•°ä¸éœ€è¦æ£€æŸ¥å¯ç”¨çŠ¶æ€
    special_params = ['period', 'start_date', 'end_date', 'custom_capital', 'initial_capital']
    
    if indicator not in enabled_indicators and indicator not in special_params:
        # å¦‚æœæŒ‡æ ‡æœªå¯ç”¨ï¼Œç›´æ¥è¿”å›Noneï¼Œä¸è¿›è¡Œè®¡ç®—
        print(f"â­ï¸ æŒ‡æ ‡ {indicator} æœªå¯ç”¨ï¼Œè·³è¿‡è®¡ç®—ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰")
        return None
    
    # ğŸ“Š æŒ‡æ ‡å·²å¯ç”¨ï¼Œå¼€å§‹è®¡ç®—
    print(f"ğŸ”§ æ­£åœ¨è®¡ç®—å¯ç”¨çš„æŒ‡æ ‡: {indicator}")
    
    # å¤„ç†å‘¨æœŸå‚æ•°
    period = extra.get('period', 'æ—¥')
    if period in ['å‘¨', 'W']:
        df = aggregate_to_weekly(df)
    elif period in ['æœˆ', 'M']:
        df = aggregate_to_monthly(df)
    elif period in ['å¹´', 'Y']:
        df = aggregate_to_yearly(df)
    
    print(f"âœ… æ­£åœ¨è®¡ç®—æŒ‡æ ‡: {indicator} (å‘¨æœŸ: {period})")
    
    # æ•°æ®åº“å­—æ®µæ˜ å°„
    db_field_map = {
        'new_listing': 'NEW_LISTING',
        'beijing_exchange': 'BEIJING_EXCHANGE',
        'main_board': 'MAIN_BOARD',
        'st': 'ST',
        'star_st': 'STAR_ST',
        'suspension': 'SUSPENSION',
        'science_board': 'SCIENCE_BOARD',
        'growth_board': 'GROWTH_BOARD',
        'delisting': 'DELISTING'
    }

    if indicator in db_field_map:
        db_field = db_field_map[indicator]
        # ä»æ•°æ®åº“ä¸­æŸ¥è¯¢å­—æ®µå€¼
        engine = create_engine(
            f"mysql+pymysql://{extra.get('db_user', 'root')}:{extra.get('db_password', '')}@{extra.get('db_host', 'localhost')}/{extra.get('db_name', 'stock')}?charset=utf8mb4"
        )
        query = f"SELECT {db_field} FROM {extra.get('db_table', 'quotes')}"
        print(f"Executing query: {query}")
        db_df = pd.read_sql(query, engine)

        # è¿”å›ç¬¦åˆæ¡ä»¶çš„ä¿¡å·å€¼
        if db_field in db_df.columns:
            return db_df[db_field].apply(lambda x: extra.get('signal_code', None) if x == 1 else None)
        else:
            return pd.Series([None]*len(db_df), index=db_df.index)

    # å‡€åˆ©æ¶¦
    if indicator == 'net_profit':
        # å‡è®¾æœ‰ä¸€åˆ— NET_PROFIT
        if 'NET_PROFIT' in df.columns:
            return df['NET_PROFIT']
        else:
            return None

    # åˆ©æ¶¦åŒæ¯”å»å¹´æ¶¨å¹…
    if indicator == 'profit_yoy':
        # å‡è®¾æœ‰ä¸€åˆ— PROFIT_YOY
        if 'PROFIT_YOY' in df.columns:
            return df['PROFIT_YOY']
        else:
            return None
    # MACDé‡‘å‰æ­»å‰ä¿¡å·æ£€æµ‹
    if indicator == 'macd_cross':
        # è®¡ç®—MACDé‡‘å‰ï¼ˆ0ï¼‰å’Œæ­»å‰ï¼ˆ1ï¼‰ä¿¡å·
        macd_result = macd.calculate(df, signal=extra.get('macd_n', 9))
        dif_val = macd_result[0]
        dea_val = macd_result[1]
        # é‡‘å‰ï¼šDIFä¸Šç©¿DEAï¼Œæ­»å‰ï¼šDIFä¸‹ç©¿DEA
        cross = ((dif_val.shift(1) < dea_val.shift(1)) & (dif_val > dea_val)).astype(int)  # é‡‘å‰ä¿¡å·
        dead = ((dif_val.shift(1) > dea_val.shift(1)) & (dif_val < dea_val)).astype(int)   # æ­»å‰ä¿¡å·
        # 0è¡¨ç¤ºé‡‘å‰ï¼Œ1è¡¨ç¤ºæ­»å‰ï¼Œå…¶ä»–ä¸ºNaN
        signal = cross.copy()
        signal[dead == 1] = 1
        signal[(cross == 0) & (dead == 0)] = None
        return signal

    # è‚¡ä¸œå‡æŒä¿¡å·ï¼ˆ2ï¼‰
    if indicator == 'holder_reduce':
        # å‡è®¾æœ‰ä¸€åˆ— HOLDER_REDUCEï¼Œ1è¡¨ç¤ºæœ‰å‡æŒï¼Œå¦åˆ™ä¸º0æˆ–NaN
        if 'HOLDER_REDUCE' in df.columns:
            return df['HOLDER_REDUCE'].apply(lambda x: 2 if x == 1 else None)
        else:
            return pd.Series([None]*len(df), index=df.index)

    # è‚¡ä¸œå¢æŒä¿¡å·ï¼ˆ3ï¼‰
    if indicator == 'holder_add':
        # å‡è®¾æœ‰ä¸€åˆ— HOLDER_ADDï¼Œ1è¡¨ç¤ºæœ‰å¢æŒï¼Œå¦åˆ™ä¸º0æˆ–NaN
        if 'HOLDER_ADD' in df.columns:
            return df['HOLDER_ADD'].apply(lambda x: 3 if x == 1 else None)
        else:
            return pd.Series([None]*len(df), index=df.index)

    # è‚¡ä¸œåˆ†çº¢ä¿¡å·ï¼ˆ4ï¼‰
    if indicator == 'holder_dividend':
        # å‡è®¾æœ‰ä¸€åˆ— HOLDER_DIVIDENDï¼Œ1è¡¨ç¤ºæœ‰åˆ†çº¢ï¼Œå¦åˆ™ä¸º0æˆ–NaN
        if 'HOLDER_DIVIDEND' in df.columns:
            return df['HOLDER_DIVIDEND'].apply(lambda x: 4 if x == 1 else None)
        else:
            return pd.Series([None]*len(df), index=df.index)

    # è¿è§„é—®è¯¢å‡½ä¿¡å·ï¼ˆ5ï¼‰
    if indicator == 'violation_letter':
        # å‡è®¾æœ‰ä¸€åˆ— VIOLATION_LETTERï¼Œ1è¡¨ç¤ºæœ‰è¿è§„é—®è¯¢å‡½ï¼Œå¦åˆ™ä¸º0æˆ–NaN
        if 'VIOLATION_LETTER' in df.columns:
            return df['VIOLATION_LETTER'].apply(lambda x: 5 if x == 1 else None)
        else:
            return pd.Series([None]*len(df), index=df.index)
    # æ–°ä¸Šå¸‚ä¿¡å·ï¼ˆ6ï¼‰
    if indicator == 'new_listing':
        if 'NEW_LISTING' in df.columns:
            return df['NEW_LISTING'].apply(lambda x: 6 if x == 1 else None)
        else:
            return pd.Series([None]*len(df), index=df.index)

    # åŒ—äº¤æ‰€ä¿¡å·ï¼ˆ7ï¼‰
    if indicator == 'beijing_exchange':
        if 'BEIJING_EXCHANGE' in df.columns:
            return df['BEIJING_EXCHANGE'].apply(lambda x: 7 if x == 1 else None)
        else:
            return pd.Series([None]*len(df), index=df.index)

    # æ²ªæ·±ä¸»æ¿ä¿¡å·ï¼ˆ8ï¼‰
    if indicator == 'main_board':
        if 'MAIN_BOARD' in df.columns:
            return df['MAIN_BOARD'].apply(lambda x: 8 if x == 1 else None)
        else:
            return pd.Series([None]*len(df), index=df.index)

    # STä¿¡å·ï¼ˆ9ï¼‰
    if indicator == 'st':
        if 'ST' in df.columns:
            return df['ST'].apply(lambda x: 9 if x == 1 else None)
        else:
            return pd.Series([None]*len(df), index=df.index)

    # *STä¿¡å·ï¼ˆ10ï¼‰
    if indicator == 'star_st':
        if 'STAR_ST' in df.columns:
            return df['STAR_ST'].apply(lambda x: 10 if x == 1 else None)
        else:
            return pd.Series([None]*len(df), index=df.index)

    # åœç‰Œä¿¡å·ï¼ˆ11ï¼‰
    if indicator == 'suspension':
        if 'SUSPENSION' in df.columns:
            return df['SUSPENSION'].apply(lambda x: 11 if x == 1 else None)
        else:
            return pd.Series([None]*len(df), index=df.index)

    # ç§‘åˆ›æ¿ä¿¡å·ï¼ˆ12ï¼‰
    if indicator == 'science_board':
        if 'SCIENCE_BOARD' in df.columns:
            return df['SCIENCE_BOARD'].apply(lambda x: 12 if x == 1 else None)
        else:
            return pd.Series([None]*len(df), index=df.index)

    # åˆ›ä¸šæ¿ä¿¡å·ï¼ˆ13ï¼‰
    if indicator == 'growth_board':
        if 'GROWTH_BOARD' in df.columns:
            return df['GROWTH_BOARD'].apply(lambda x: 13 if x == 1 else None)
        else:
            return pd.Series([None]*len(df), index=df.index)

    # é€€å¸‚ä¿¡å·ï¼ˆ14ï¼‰
    if indicator == 'delisting':
        if 'DELISTING' in df.columns:
            return df['DELISTING'].apply(lambda x: 14 if x == 1 else None)
        else:
            return pd.Series([None]*len(df), index=df.index)

    # å¼€ç›˜ä»·å¯¹æ¯”
    if indicator == 'open_price' or indicator == 'open':
        if 'OPEN' in df.columns:
            return df['OPEN']
        elif 'open' in df.columns:
            return df['open']
        else:
            return pd.Series([None]*len(df), index=df.index)

    # æ”¶ç›˜ä»·å¯¹æ¯”  
    if indicator == 'close_price' or indicator == 'close':
        if 'CLOSE' in df.columns:
            return df['CLOSE']
        elif 'close' in df.columns:
            return df['close']
        else:
            return pd.Series([None]*len(df), index=df.index)

    # æœ€é«˜ä»·å¯¹æ¯”
    if indicator == 'high_price' or indicator == 'high':
        if 'HIGH' in df.columns:
            return df['HIGH']
        elif 'high' in df.columns:
            return df['high']
        else:
            return pd.Series([None]*len(df), index=df.index)

    # æœ€ä½ä»·å¯¹æ¯”
    if indicator == 'low_price' or indicator == 'low':
        if 'LOW' in df.columns:
            return df['LOW']
        elif 'low' in df.columns:
            return df['low']
        else:
            return pd.Series([None]*len(df), index=df.index)

    # æ—¥æˆäº¤å‡ä»·å¯¹æ¯”
    if indicator == 'avg_price':
        # æ—¥æˆäº¤å‡ä»· = æˆäº¤é¢ / æˆäº¤é‡
        if 'AMOUNT' in df.columns and 'VOLUME' in df.columns:
            # é¿å…é™¤é›¶é”™è¯¯
            volume_nonzero = df['VOLUME'].replace(0, 1)
            return df['AMOUNT'] / volume_nonzero
        elif 'AVG_PRICE' in df.columns:
            return df['AVG_PRICE']
        else:
            # å¦‚æœæ²¡æœ‰æˆäº¤é¢ï¼Œç”¨(æœ€é«˜ä»·+æœ€ä½ä»·+æ”¶ç›˜ä»·)/3ä¼°ç®—
            if 'HIGH' in df.columns and 'LOW' in df.columns and 'CLOSE' in df.columns:
                return (df['HIGH'] + df['LOW'] + df['CLOSE']) / 3
            else:
                return pd.Series([None]*len(df), index=df.index)

    # æ¶¨å¹…å¯¹æ¯”
    if indicator == 'change_rate' or indicator == 'pct_change':
        if 'CHANGE_RATE' in df.columns:
            return df['CHANGE_RATE']
        elif 'PCT_CHANGE' in df.columns:
            return df['PCT_CHANGE']
        elif 'CLOSE' in df.columns:
            # è®¡ç®—æ¶¨å¹… = (ä»Šæ”¶ç›˜ä»· - æ˜¨æ”¶ç›˜ä»·) / æ˜¨æ”¶ç›˜ä»· * 100
            prev_close = df['CLOSE'].shift(1)
            change_rate = ((df['CLOSE'] - prev_close) / prev_close * 100).fillna(0)
            return change_rate
        else:
            return pd.Series([None]*len(df), index=df.index)

    # é‡æ¯”å¯¹æ¯”
    if indicator == 'volume_ratio':
        if 'VOLUME_RATIO' in df.columns:
            return df['VOLUME_RATIO']
        elif 'VOLUME' in df.columns:
            # é‡æ¯” = å½“æ—¥æˆäº¤é‡ / è¿‡å»5æ—¥å¹³å‡æˆäº¤é‡
            avg_volume_5 = df['VOLUME'].rolling(window=5).mean()
            volume_ratio = (df['VOLUME'] / avg_volume_5).fillna(1)
            return volume_ratio
        else:
            return pd.Series([None]*len(df), index=df.index)

    # æˆäº¤é¢å¯¹æ¯”
    if indicator == 'amount' or indicator == 'turnover':
        if 'AMOUNT' in df.columns:
            return df['AMOUNT']
        elif 'TURNOVER' in df.columns:
            return df['TURNOVER']
        elif 'CLOSE' in df.columns and 'VOLUME' in df.columns:
            # æˆäº¤é¢ = æ”¶ç›˜ä»· * æˆäº¤é‡
            return df['CLOSE'] * df['VOLUME']
        else:
            return pd.Series([None]*len(df), index=df.index)

    # æ¢æ‰‹ç‡å¯¹æ¯”
    if indicator == 'turnover_rate':
        if 'TURNOVER_RATE' in df.columns:
            return df['TURNOVER_RATE']
        elif 'VOLUME' in df.columns and 'TOTAL_SHARE' in df.columns:
            # æ¢æ‰‹ç‡ = æˆäº¤é‡ / æµé€šè‚¡æœ¬ * 100
            turnover_rate = (df['VOLUME'] / df['TOTAL_SHARE'] * 100).fillna(0)
            return turnover_rate
        else:
            return pd.Series([None]*len(df), index=df.index)

    # ä¹°å…¥ä¿¡å·ï¼ˆ15ï¼‰- è°ƒç”¨ä¿¡å·åº“
    if indicator == 'buy_signal':
        # ä½¿ç”¨ä¿¡å·åº“ç”Ÿæˆä¹°å…¥ä¿¡å·
        stock_code = extra.get('stock_code', 'UNKNOWN')
        signal_type = extra.get('buy_signal_type', 'basic')
        return generate_buy_signal(stock_code, df, signal_type, **extra)

    # å–å‡ºä¿¡å·ï¼ˆ16ï¼‰- è°ƒç”¨ä¿¡å·åº“
    if indicator == 'sell_signal':
        # ä½¿ç”¨ä¿¡å·åº“ç”Ÿæˆå–å‡ºä¿¡å·
        stock_code = extra.get('stock_code', 'UNKNOWN')
        signal_type = extra.get('sell_signal_type', 'basic')
        return generate_sell_signal(stock_code, df, signal_type, **extra)

    # æˆäº¤é‡æŒ‡æ ‡
    if indicator == 'volume':
        if 'VOLUME' in df.columns:
            return df['VOLUME']
        elif 'volume' in df.columns:
            return df['volume']
        else:
            return pd.Series([None]*len(df), index=df.index)

    # ç»Ÿä¸€é€šè¿‡ indicators.__init__.py å¯¼å…¥çš„å‡½æ•°å¯¹è±¡è¿›è¡Œè°ƒç”¨
    # å­—æ®µå…¼å®¹å¤„ç†ï¼Œè‡ªåŠ¨é€‚é…å°å†™å’Œå¤§å†™
    # å­—æ®µå…¼å®¹å¤„ç†ï¼Œæ”¯æŒå°å†™ã€é¦–å­—æ¯å¤§å†™ã€å…¨å¤§å†™
    col_map = {}
    for col in ['low', 'high', 'close', 'open', 'volume']:
        for variant in [col, col.capitalize(), col.upper()]:
            if variant in df.columns:
                col_map[variant] = col.upper()
    df = df.rename(columns=col_map)
    if indicator == 'ma':
        n = extra.get('ma_n', 5)
        result = ma.calculate(df, N=n)
        return result.round(2)
    elif indicator == 'dif':
        n = extra.get('dif_n', 12)
        result = dif.dif(df['CLOSE'], short=n)
        return result.round(2)
    elif indicator == 'dea':
        n = extra.get('dea_n', 9)
        result = dea.dea(df['CLOSE'], m=n)
        return result.round(2)
    elif indicator == 'macd':
        n = extra.get('macd_n', 9)
        result = macd.calculate(df, signal=n)
        if isinstance(result, tuple):
            return tuple(r.round(2) for r in result)
        else:
            return result.round(2)
    elif indicator == 'kdj':
        n = extra.get('k_n', 9)
        k_val, d_val, j_val = kdj.kdj(df, n=n)
        return k_val.round(2), d_val.round(2), j_val.round(2)
    elif indicator == 'k':
        n = extra.get('k_n', 9)
        k_val, _, _ = kdj.kdj(df, n=n)
        return k_val.round(2)
    elif indicator == 'd':
        n = extra.get('d_n', 9)
        _, d_val, _ = kdj.kdj(df, n=n)
        return d_val.round(2)
    elif indicator == 'j':
        n = extra.get('j_n', 9)
        _, _, j_val = kdj.kdj(df, n=n)
        return j_val.round(2)
    # å…¶ä»–æŒ‡æ ‡...

def filter_stocks(indicator_names, conditions, data_source, extra_indicators=None):
    """
    indicator_names: ['macd', 'rsi', ...]
    conditions: {'macd': lambda x: x > 0, 'rsi': lambda x: x < 70}
    data_source: å¯ä»¥æ˜¯ csv è·¯å¾„ã€mysql é…ç½®å­—å…¸ æˆ– 'database' å­—ç¬¦ä¸²
    extra_indicators: é¢å¤–å‚æ•°ï¼ŒåŒ…å«å¯ç”¨æŒ‡æ ‡ã€å‘¨æœŸã€è‡ªå®šä¹‰èµ„é‡‘ç­‰
    è¿”å›ï¼šç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨DataFrame
    """
    # è·å–é¢å¤–å‚æ•°
    if extra_indicators is None:
        extra_indicators = {}
    
    enabled_indicators = extra_indicators.get('enabled_indicators', indicator_names)
    period = extra_indicators.get('period', 'æ—¥')
    custom_capital = extra_indicators.get('custom_capital', 100000)
    
    print(f"ç­›é€‰å‚æ•° - å¯ç”¨æŒ‡æ ‡: {enabled_indicators}, å‘¨æœŸ: {period}, èµ„é‡‘: {custom_capital}")
    
    # åˆ¤æ–­æ•°æ®æºç±»å‹
    if isinstance(data_source, str):
        if data_source.endswith('.csv'):
            # CSVæ–‡ä»¶æ¨¡å¼
            print(f"ä½¿ç”¨CSVæ–‡ä»¶æ¨¡å¼: {data_source}")
            df = get_csv_df(data_source)
        elif data_source == 'database':
            # æ•°æ®åº“æ¨¡å¼ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
            print("ä½¿ç”¨æ•°æ®åº“æ¨¡å¼")
            mysql_config = {
                'host': 'localhost',
                'user': 'root',
                'password': '9',
                'database': 'stock',
                'table': 'quotes',
                'charset': 'utf8mb4'
            }
            df = get_mysql_df(**mysql_config)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æºå­—ç¬¦ä¸²: {data_source}")
    elif isinstance(data_source, dict):
        # MySQLé…ç½®å­—å…¸æ¨¡å¼
        print("ä½¿ç”¨MySQLé…ç½®å­—å…¸æ¨¡å¼")
        df = get_mysql_df(**data_source)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æºç±»å‹: {type(data_source)}")
        
    # å­—æ®µæ˜ å°„ï¼Œé€‚é…æŒ‡æ ‡æ¨¡å—
    df = df.rename(columns={
        'price': 'CLOSE',   # å…¼å®¹æ•°æ®åº“
        'close': 'CLOSE',   # å…¼å®¹csv
        'open': 'OPEN',
        'high': 'HIGH',
        'low': 'LOW',
        'volume': 'VOLUME',
        'amount': 'AMOUNT',     # æˆäº¤é¢
        'turnover': 'AMOUNT',   # æˆäº¤é¢åˆ«å
        'avg_price': 'AVG_PRICE',  # æ—¥æˆäº¤å‡ä»·
        'change_rate': 'CHANGE_RATE',  # æ¶¨å¹…
        'pct_change': 'CHANGE_RATE',   # æ¶¨å¹…åˆ«å
        'volume_ratio': 'VOLUME_RATIO',  # é‡æ¯”
        'turnover_rate': 'TURNOVER_RATE',  # æ¢æ‰‹ç‡
        'total_share': 'TOTAL_SHARE'   # æµé€šè‚¡æœ¬
    })
    
    # å‘¨æœŸåˆ†å‰²é€‚é… - ä¼ é€’é¢å¤–å‚æ•°ç»™get_indicator
    if period in ['å‘¨', 'W']:
        df = aggregate_to_weekly(df)
    elif period in ['æœˆ', 'M']:
        df = aggregate_to_monthly(df)
    elif period in ['å¹´', 'Y']:
        df = aggregate_to_yearly(df)
    # æ—¥çº¿æ— éœ€å¤„ç†ï¼Œç›´æ¥ç”¨åŸå§‹æ•°æ®
    
    # å°†å‘¨æœŸå’Œå¯ç”¨æŒ‡æ ‡ä¿¡æ¯ä¼ é€’ç»™get_indicator
    extra_indicators['period'] = period
    extra_indicators['enabled_indicators'] = enabled_indicators
    extra_indicators['custom_capital'] = custom_capital
    # æ—¶é—´ç­›é€‰æœºåˆ¶ï¼ˆå¯é€‰å‚æ•°ï¼‰
    import datetime
    start_date = extra_indicators.get('start_date') if extra_indicators else None
    end_date = extra_indicators.get('end_date') if extra_indicators else None
    if start_date:
        df = df[df['date'] >= start_date]
    if end_date:
        df = df[df['date'] <= end_date]
    
    # é‡ç½®ç´¢å¼•ç¡®ä¿ä¸€è‡´æ€§
    df = df.reset_index(drop=True)
    
    indicator_dir = os.path.join(os.path.dirname(__file__), 'indicators')
    result_mask = pd.Series([True] * len(df), index=df.index)
    
    # å…ˆè®¡ç®—æ‰€æœ‰éœ€è¦çš„æŒ‡æ ‡å€¼ï¼Œå­˜å‚¨åˆ°DataFrameä¸­
    calculated_indicators = {}
    
    # åˆå¹¶æ‰€æœ‰æŒ‡æ ‡å
    all_indicators = set(indicator_names)
    if extra_indicators:
        all_indicators.update(extra_indicators)
    
    # ç¬¬ä¸€è½®ï¼šè®¡ç®—æ‰€æœ‰æŒ‡æ ‡å€¼
    for name in all_indicators:
        try:
            if name == 'four_ma_long':
                # å››å‘¨æœŸå¤šå¤´æ’åˆ—ï¼šMA5 > MA10 > MA20 > MA60
                ma5 = df['CLOSE'].rolling(window=5).mean()
                ma10 = df['CLOSE'].rolling(window=10).mean()
                ma20 = df['CLOSE'].rolling(window=20).mean()
                ma60 = df['CLOSE'].rolling(window=60).mean()
                values = (ma5 > ma10) & (ma10 > ma20) & (ma20 > ma60)
                calculated_indicators[name] = values
                df[f'{name}_indicator'] = values
            elif name == 'macd_cross':
                values = get_indicator('macd_cross', df, extra_indicators if extra_indicators else {})
                calculated_indicators[name] = values
                df[f'{name}_indicator'] = values
            elif name == 'net_profit':
                values = get_indicator('net_profit', df, extra_indicators if extra_indicators else {})
                calculated_indicators[name] = values
                df[f'{name}_indicator'] = values
            elif name == 'profit_yoy':
                values = get_indicator('profit_yoy', df, extra_indicators if extra_indicators else {})
                calculated_indicators[name] = values
                df[f'{name}_indicator'] = values
            # ä»·æ ¼ç›¸å…³æŒ‡æ ‡
            elif name in ['open_price', 'open']:
                values = get_indicator('open_price', df, extra_indicators if extra_indicators else {})
                calculated_indicators[name] = values
                df[f'{name}_indicator'] = values
            elif name in ['close_price', 'close']:
                values = get_indicator('close_price', df, extra_indicators if extra_indicators else {})
                calculated_indicators[name] = values
                df[f'{name}_indicator'] = values
            elif name in ['high_price', 'high']:
                values = get_indicator('high_price', df, extra_indicators if extra_indicators else {})
                calculated_indicators[name] = values
                df[f'{name}_indicator'] = values
            elif name in ['low_price', 'low']:
                values = get_indicator('low_price', df, extra_indicators if extra_indicators else {})
                calculated_indicators[name] = values
                df[f'{name}_indicator'] = values
            elif name == 'avg_price':
                values = get_indicator('avg_price', df, extra_indicators if extra_indicators else {})
                calculated_indicators[name] = values
                df[f'{name}_indicator'] = values
            elif name in ['change_rate', 'pct_change']:
                values = get_indicator('change_rate', df, extra_indicators if extra_indicators else {})
                calculated_indicators[name] = values
                df[f'{name}_indicator'] = values
            elif name == 'volume_ratio':
                values = get_indicator('volume_ratio', df, extra_indicators if extra_indicators else {})
                calculated_indicators[name] = values
                df[f'{name}_indicator'] = values
            elif name in ['amount', 'turnover']:
                values = get_indicator('amount', df, extra_indicators if extra_indicators else {})
                calculated_indicators[name] = values
                df[f'{name}_indicator'] = values
            elif name == 'turnover_rate':
                values = get_indicator('turnover_rate', df, extra_indicators if extra_indicators else {})
                calculated_indicators[name] = values
                df[f'{name}_indicator'] = values
            elif name in ['volume']:  # å¤„ç†æˆäº¤é‡
                values = df['VOLUME'] if 'VOLUME' in df.columns else None
                calculated_indicators[name] = values
                df[f'{name}_indicator'] = values
            else:
                values = get_indicator(name, df, extra_indicators if extra_indicators else {})
                calculated_indicators[name] = values
                if values is not None:
                    df[f'{name}_indicator'] = values
                    
        except Exception as e:
            print(f'æŒ‡æ ‡ {name} è®¡ç®—å¤±è´¥: {e}')
            continue
    
    # ç¬¬äºŒè½®ï¼šåº”ç”¨ç­›é€‰æ¡ä»¶
    for name in all_indicators:
        try:
            if name not in calculated_indicators:
                continue
                
            values = calculated_indicators[name]
            if values is None:
                continue
                
            # è‡ªåŠ¨é€‚é…è¿”å›å€¼ç±»å‹
            if isinstance(values, tuple):
                # KDJç›¸å…³ï¼ŒæŒ‰ name è¿”å› k/d/j
                if name == 'kdj':
                    values = values[0]  # é»˜è®¤å–K
                elif name == 'k':
                    values = values[0]
                elif name == 'd':
                    values = values[1]
                elif name == 'j':
                    values = values[2]
                else:
                    values = values[0]
            if isinstance(values, pd.DataFrame):
                values = values.iloc[:, 0]
            cond = conditions.get(name, lambda x: True)
            # å¦‚æœæ˜¯ä»·æ ¼ã€æˆäº¤ç›¸å…³æŒ‡æ ‡ï¼Œä¸”æ¡ä»¶ä¸ºdictï¼Œè‡ªåŠ¨ç”¨compare.py
            price_volume_indicators = [
                'net_profit', 'profit_yoy', 'open_price', 'open', 'close_price', 'close',
                'high_price', 'high', 'low_price', 'low', 'avg_price', 'change_rate', 
                'pct_change', 'volume_ratio', 'amount', 'turnover', 'turnover_rate'
            ]
            
            if name in price_volume_indicators and isinstance(cond, dict) and 'op' in cond and 'value' in cond:
                import compare
                op = cond['op']
                val = cond['value']
                print(f"å¤„ç†æŒ‡æ ‡ {name}: {op} {val}")
                
                if op == '>':
                    mask = compare.greater(values, val)
                elif op == '<':
                    mask = compare.less(values, val)
                elif op == '>=':
                    mask = compare.greater_equal(values, val)
                elif op == '<=':
                    mask = compare.less_equal(values, val)
                elif op == '=':
                    mask = compare.equal(values, val)
                else:
                    mask = pd.Series([True]*len(values), index=values.index)
            else:
                if callable(cond):
                    mask = cond(values)
                else:
                    # å¦‚æœæ¡ä»¶ä¸æ˜¯å¯è°ƒç”¨çš„ï¼Œåˆ™è·³è¿‡
                    mask = pd.Series([True]*len(values), index=values.index)
            if not isinstance(mask, pd.Series):
                # ç¡®ä¿maskæ˜¯å¸ƒå°”ç±»å‹çš„åˆ—è¡¨æˆ–æ•°ç»„
                try:
                    if hasattr(mask, '__iter__') and not isinstance(mask, (str, bytes)):
                        mask = pd.Series(list(mask), index=df.index)  # type: ignore
                    else:
                        mask = pd.Series([bool(mask)] * len(df), index=df.index)
                except (TypeError, ValueError):
                    # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œé»˜è®¤ä¸º True
                    mask = pd.Series([True] * len(df), index=df.index)
            # ç¡®ä¿maskå’Œresult_maskçš„ç´¢å¼•åŒ¹é…
            mask = mask.reindex(df.index, fill_value=False)
            result_mask &= mask
        except Exception as e:
            print(f'æŒ‡æ ‡ {name} åŠ è½½å¤±è´¥: {e}')
    return df[result_mask]

# ç¤ºä¾‹ç”¨æ³•

if __name__ == '__main__':
    import sys, json, os
    # æ”¯æŒå‰ç«¯ä¼ é€’å‚æ•°ï¼šæŒ‡æ ‡ã€æ¡ä»¶ã€æ—¶é—´åŒºé—´ã€æ•°æ®è·¯å¾„
    indicator_names = os.environ.get('INDICATORS')
    if indicator_names:
        try:
            indicator_names = json.loads(indicator_names)
        except:
            indicator_names = indicator_names.split(',')
    else:
        indicator_names = []
    conditions_str = os.environ.get('CONDITIONS')
    if conditions_str:
        conditions = json.loads(conditions_str)
        # æ”¯æŒå‰ç«¯ä¼ é€’æ¯”è¾ƒè¡¨è¾¾å¼ï¼Œå¦‚ {'OPEN': {'op': '>', 'value': 10}}
        for k, v in conditions.items():
            if isinstance(v, dict) and 'op' in v and 'value' in v:
                op = v['op']
                val = v['value']
                if op == '>':
                    conditions[k] = lambda x, val=val: compare.greater(x, val)
                elif op == '<':
                    conditions[k] = lambda x, val=val: compare.less(x, val)
                elif op == '>=':
                    conditions[k] = lambda x, val=val: compare.greater_equal(x, val)
                elif op == '<=':
                    conditions[k] = lambda x, val=val: compare.less_equal(x, val)
                elif op == '=':
                    conditions[k] = lambda x, val=val: compare.equal(x, val)
                else:
                    conditions[k] = lambda x: True
            elif isinstance(v, str):
                conditions[k] = eval(f'lambda x: {v}')
    else:
        conditions = {}
    start_date = os.environ.get('START_DATE')
    end_date = os.environ.get('END_DATE')
    extra = {}
    if start_date:
        extra['start_date'] = start_date
    if end_date:
        extra['end_date'] = end_date
    # æ•°æ®åº“é…ç½®
    mysql_config = {
        'host': 'localhost',
        'user': 'root',
        'password': '9',
        'database': 'stock',
        'table': 'quotes',
        'charset': 'utf8mb4'
    }
    print(f'MySQLé…ç½®: {mysql_config}')
    print(f'æŒ‡æ ‡: {indicator_names}')
    print(f'æ¡ä»¶: {conditions_str}')
    print(f'æ—¶é—´åŒºé—´: {extra}')
    # è¯»å–æ•°æ®åº“æ•°æ®
    df = get_mysql_df(
        host=mysql_config['host'],
        user=mysql_config['user'],
        password=mysql_config['password'],
        database=mysql_config['database'],
        table=mysql_config['table'],
        charset=mysql_config['charset']
    )
    df = df.rename(columns={
        'price': 'CLOSE',
        'close': 'CLOSE',
        'open': 'OPEN',
        'high': 'HIGH',
        'low': 'LOW',
        'volume': 'VOLUME',
        'amount': 'AMOUNT',     # æˆäº¤é¢
        'turnover': 'AMOUNT',   # æˆäº¤é¢åˆ«å
        'avg_price': 'AVG_PRICE',  # æ—¥æˆäº¤å‡ä»·
        'change_rate': 'CHANGE_RATE',  # æ¶¨å¹…
        'pct_change': 'CHANGE_RATE',   # æ¶¨å¹…åˆ«å
        'volume_ratio': 'VOLUME_RATIO',  # é‡æ¯”
        'turnover_rate': 'TURNOVER_RATE',  # æ¢æ‰‹ç‡
        'total_share': 'TOTAL_SHARE'   # æµé€šè‚¡æœ¬
    })
    
    # è®¡ç®—è¡ç”Ÿå­—æ®µï¼ˆå¦‚æœåŸå§‹æ•°æ®æ²¡æœ‰çš„è¯ï¼‰
    if 'AVG_PRICE' not in df.columns and 'AMOUNT' in df.columns and 'VOLUME' in df.columns:
        # æ—¥æˆäº¤å‡ä»· = æˆäº¤é¢ / æˆäº¤é‡
        volume_nonzero = df['VOLUME'].replace(0, 1)
        df['AVG_PRICE'] = df['AMOUNT'] / volume_nonzero
    
    if 'CHANGE_RATE' not in df.columns and 'CLOSE' in df.columns:
        # è®¡ç®—æ¶¨å¹…
        prev_close = df['CLOSE'].shift(1)
        df['CHANGE_RATE'] = ((df['CLOSE'] - prev_close) / prev_close * 100).fillna(0)
    
    if 'VOLUME_RATIO' not in df.columns and 'VOLUME' in df.columns:
        # è®¡ç®—é‡æ¯”
        avg_volume_5 = df['VOLUME'].rolling(window=5).mean()
        df['VOLUME_RATIO'] = (df['VOLUME'] / avg_volume_5).fillna(1)
    
    if 'AMOUNT' not in df.columns and 'CLOSE' in df.columns and 'VOLUME' in df.columns:
        # è®¡ç®—æˆäº¤é¢
        df['AMOUNT'] = df['CLOSE'] * df['VOLUME']
    
    if 'TURNOVER_RATE' not in df.columns and 'VOLUME' in df.columns and 'TOTAL_SHARE' in df.columns:
        # è®¡ç®—æ¢æ‰‹ç‡
        df['TURNOVER_RATE'] = (df['VOLUME'] / df['TOTAL_SHARE'] * 100).fillna(0)
    # åˆå¹¶æ‰€æœ‰æ¯”è¾ƒç»“æœåˆ° DataFrame
    compare_results = {}
    for field, cond_func in conditions.items():
        if field in df.columns:
            compare_results[f'{field}_compare_result'] = df[field].apply(cond_func)
    
    # åˆå¹¶æ¯”è¾ƒç»“æœåˆ° df
    for col, result in compare_results.items():
        df[col] = result
    
    # åº”ç”¨ç­›é€‰æ¡ä»¶
    if compare_results:
        # è·å–æ‰€æœ‰æ¯”è¾ƒç»“æœåˆ—
        condition_columns = list(compare_results.keys())
        # åˆ›å»ºå¸ƒå°”ç´¢å¼•ï¼šæ‰€æœ‰æ¡ä»¶éƒ½ä¸ºTrueçš„è¡Œ
        if condition_columns:
            mask = df[condition_columns[0]]
            for col in condition_columns[1:]:
                mask = mask & df[col]
            df_filtered = df[mask]
        else:
            df_filtered = df.copy()
    else:
        df_filtered = df.copy()
    
    # è¾“å‡ºæ‰€æœ‰å­—æ®µæ¯”è¾ƒç»“æœåˆ°å‰ç«¯ï¼ˆæ§åˆ¶å°ï¼‰
    if compare_results:
        print('æ‰€æœ‰å­—æ®µæ¯”è¾ƒç»“æœï¼ˆç­›é€‰åï¼‰:')
        print(df_filtered[[col for col in compare_results.keys() if col in df_filtered.columns]])
    
    log_path = '/home/liu/æ¡Œé¢/stock-main/backend/filter_stocks_result.log'
    df_filtered.to_csv(log_path, index=False, encoding='utf-8')
    print(f'ç­›é€‰ç»“æœå·²ä¿å­˜åˆ°: {log_path}')


def aggregate_to_weekly(df, start_date=None, end_date=None):
    """
    å°†æ—¥Kçº¿æ•°æ®èšåˆä¸ºå‘¨Kçº¿
    
    Args:
        df: æ•°æ®DataFrame
        start_date: å¼€å§‹æ—¥æœŸï¼ˆå¯é€‰ï¼‰
        end_date: ç»“æŸæ—¥æœŸï¼ˆå¯é€‰ï¼‰
    """
    try:
        df = df.copy()
        
        # ç¡®ä¿æœ‰æ—¥æœŸåˆ—
        if 'date' not in df.columns and 'DATE' not in df.columns:
            print("è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ°æ—¥æœŸåˆ—ï¼Œæ— æ³•è¿›è¡Œå‘¨èšåˆ")
            return df
            
        date_col = 'date' if 'date' in df.columns else 'DATE'
        df[date_col] = pd.to_datetime(df[date_col])
        
        # å¦‚æœæä¾›äº†æ—¥æœŸèŒƒå›´ï¼Œå…ˆè¿›è¡Œç­›é€‰
        if start_date is not None:
            # ç¡®ä¿start_dateæ˜¯pandas datetimeç±»å‹
            start_date = pd.to_datetime(start_date)
            df = df[df[date_col] >= start_date]
            
        if end_date is not None:
            # ç¡®ä¿end_dateæ˜¯pandas datetimeç±»å‹
            end_date = pd.to_datetime(end_date)
            df = df[df[date_col] <= end_date]
        
        df.set_index(date_col, inplace=True)
        
        # å‘¨èšåˆè§„åˆ™
        agg_rules = {
            'OPEN': 'first',     # å¼€ç›˜ä»·å–ç¬¬ä¸€å¤©
            'open': 'first',
            'HIGH': 'max',       # æœ€é«˜ä»·å–æœ€å¤§å€¼
            'high': 'max',
            'LOW': 'min',        # æœ€ä½ä»·å–æœ€å°å€¼
            'low': 'min',
            'CLOSE': 'last',     # æ”¶ç›˜ä»·å–æœ€åä¸€å¤©
            'close': 'last',
            'VOLUME': 'sum',     # æˆäº¤é‡ç´¯åŠ 
            'volume': 'sum',
            'AMOUNT': 'sum',     # æˆäº¤é¢ç´¯åŠ 
            'amount': 'sum',
            'turnover': 'sum',
            'code': 'first',     # è‚¡ç¥¨ä»£ç å–ç¬¬ä¸€ä¸ª
            'name': 'first',     # è‚¡ç¥¨åç§°å–ç¬¬ä¸€ä¸ª
            'change': 'last',    # å˜åŒ–é¢å–æœ€åä¸€å¤©
            'change_rate': 'last', # å˜åŒ–ç‡å–æœ€åä¸€å¤©
            'amplitude': 'max',   # æŒ¯å¹…å–æœ€å¤§å€¼
            'turnover_rate': 'sum' # æ¢æ‰‹ç‡ç´¯åŠ 
        }
        
        # åªèšåˆå­˜åœ¨çš„åˆ—
        existing_agg_rules = {k: v for k, v in agg_rules.items() if k in df.columns}
        
        if existing_agg_rules:
            # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„è¿›è¡Œèšåˆ
            if 'code' in df.columns:
                # å…ˆæŒ‰codeåˆ†ç»„ï¼Œå†å¯¹æ¯ç»„è¿›è¡Œå‘¨èšåˆ
                grouped_dfs = []
                for code, group in df.groupby('code'):
                    group_copy = group.copy()
                    # å¯¹æ¯åªè‚¡ç¥¨å•ç‹¬è¿›è¡Œå‘¨èšåˆ
                    weekly_group = group_copy.resample('W').agg(existing_agg_rules)
                    weekly_group.reset_index(inplace=True)
                    # ç¡®ä¿è‚¡ç¥¨ä»£ç æ­£ç¡®ä¼ é€’
                    weekly_group['code'] = code
                    if 'name' in group_copy.columns:
                        weekly_group['name'] = group_copy['name'].iloc[0]
                    grouped_dfs.append(weekly_group)
                
                if grouped_dfs:
                    weekly_df = pd.concat(grouped_dfs, ignore_index=True)
                    print(f"æˆåŠŸå°† {len(df)} è¡Œæ—¥æ•°æ®èšåˆä¸º {len(weekly_df)} è¡Œå‘¨æ•°æ®")
                    return weekly_df
            else:
                weekly_df = df.resample('W').agg(existing_agg_rules)
                weekly_df.reset_index(inplace=True)
                print(f"æˆåŠŸå°† {len(df)} è¡Œæ—¥æ•°æ®èšåˆä¸º {len(weekly_df)} è¡Œå‘¨æ•°æ®")
                return weekly_df
        else:
            print("è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ°å¯èšåˆçš„OHLCVåˆ—")
            return df
            
    except Exception as e:
        print(f"å‘¨èšåˆå¤±è´¥: {e}")
        print(f"é”™è¯¯è¯¦ç»†ä¿¡æ¯: start_dateç±»å‹={type(start_date)}, end_dateç±»å‹={type(end_date)}")
        import traceback
        traceback.print_exc()
        return df


def aggregate_to_monthly(df, start_date=None, end_date=None):
    """
    å°†æ—¥Kçº¿æ•°æ®èšåˆä¸ºæœˆKçº¿
    
    Args:
        df: æ•°æ®DataFrame
        start_date: å¼€å§‹æ—¥æœŸï¼ˆå¯é€‰ï¼‰
        end_date: ç»“æŸæ—¥æœŸï¼ˆå¯é€‰ï¼‰
    """
    try:
        df = df.copy()
        
        # ç¡®ä¿æœ‰æ—¥æœŸåˆ—
        if 'date' not in df.columns and 'DATE' not in df.columns:
            print("è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ°æ—¥æœŸåˆ—ï¼Œæ— æ³•è¿›è¡Œæœˆèšåˆ")
            return df
            
        date_col = 'date' if 'date' in df.columns else 'DATE'
        df[date_col] = pd.to_datetime(df[date_col])
        
        # å¦‚æœæä¾›äº†æ—¥æœŸèŒƒå›´ï¼Œå…ˆè¿›è¡Œç­›é€‰
        if start_date is not None:
            # ç¡®ä¿start_dateæ˜¯pandas datetimeç±»å‹
            start_date = pd.to_datetime(start_date)
            df = df[df[date_col] >= start_date]
            
        if end_date is not None:
            # ç¡®ä¿end_dateæ˜¯pandas datetimeç±»å‹
            end_date = pd.to_datetime(end_date)
            df = df[df[date_col] <= end_date]
        
        df.set_index(date_col, inplace=True)
        
        # æœˆèšåˆè§„åˆ™
        agg_rules = {
            'OPEN': 'first',     # å¼€ç›˜ä»·å–ç¬¬ä¸€å¤©
            'open': 'first',
            'HIGH': 'max',       # æœ€é«˜ä»·å–æœ€å¤§å€¼
            'high': 'max',
            'LOW': 'min',        # æœ€ä½ä»·å–æœ€å°å€¼
            'low': 'min',
            'CLOSE': 'last',     # æ”¶ç›˜ä»·å–æœ€åä¸€å¤©
            'close': 'last',
            'VOLUME': 'sum',     # æˆäº¤é‡ç´¯åŠ 
            'volume': 'sum',
            'AMOUNT': 'sum',     # æˆäº¤é¢ç´¯åŠ 
            'amount': 'sum',
            'turnover': 'sum',
            'code': 'first',     # è‚¡ç¥¨ä»£ç å–ç¬¬ä¸€ä¸ª
            'name': 'first',     # è‚¡ç¥¨åç§°å–ç¬¬ä¸€ä¸ª
            'change': 'last',    # å˜åŒ–é¢å–æœ€åä¸€å¤©
            'change_rate': 'last', # å˜åŒ–ç‡å–æœ€åä¸€å¤©
            'amplitude': 'max',   # æŒ¯å¹…å–æœ€å¤§å€¼
            'turnover_rate': 'sum' # æ¢æ‰‹ç‡ç´¯åŠ 
        }
        
        # åªèšåˆå­˜åœ¨çš„åˆ—
        existing_agg_rules = {k: v for k, v in agg_rules.items() if k in df.columns}
        
        if existing_agg_rules:
            # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„è¿›è¡Œèšåˆ
            if 'code' in df.columns:
                # å…ˆæŒ‰codeåˆ†ç»„ï¼Œå†å¯¹æ¯ç»„è¿›è¡Œæœˆèšåˆ
                grouped_dfs = []
                for code, group in df.groupby('code'):
                    group_copy = group.copy()
                    # å¯¹æ¯åªè‚¡ç¥¨å•ç‹¬è¿›è¡Œæœˆèšåˆ
                    monthly_group = group_copy.resample('ME').agg(existing_agg_rules)
                    monthly_group.reset_index(inplace=True)
                    # ç¡®ä¿è‚¡ç¥¨ä»£ç æ­£ç¡®ä¼ é€’
                    monthly_group['code'] = code
                    if 'name' in group_copy.columns:
                        monthly_group['name'] = group_copy['name'].iloc[0]
                    grouped_dfs.append(monthly_group)
                
                if grouped_dfs:
                    monthly_df = pd.concat(grouped_dfs, ignore_index=True)
                    print(f"æˆåŠŸå°† {len(df)} è¡Œæ—¥æ•°æ®èšåˆä¸º {len(monthly_df)} è¡Œæœˆæ•°æ®")
                    return monthly_df
            else:
                monthly_df = df.resample('ME').agg(existing_agg_rules)
                monthly_df.reset_index(inplace=True)
                print(f"æˆåŠŸå°† {len(df)} è¡Œæ—¥æ•°æ®èšåˆä¸º {len(monthly_df)} è¡Œæœˆæ•°æ®")
                return monthly_df
        else:
            print("è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ°å¯èšåˆçš„OHLCVåˆ—")
            return df
            
    except Exception as e:
        print(f"æœˆèšåˆå¤±è´¥: {e}")
        print(f"é”™è¯¯è¯¦ç»†ä¿¡æ¯: start_dateç±»å‹={type(start_date)}, end_dateç±»å‹={type(end_date)}")
        import traceback
        traceback.print_exc()
        return df


def aggregate_to_yearly(df, start_date=None, end_date=None):
    """
    å°†æ—¥Kçº¿æ•°æ®èšåˆä¸ºå¹´Kçº¿
    
    Args:
        df: æ•°æ®DataFrame
        start_date: å¼€å§‹æ—¥æœŸï¼ˆå¯é€‰ï¼‰
        end_date: ç»“æŸæ—¥æœŸï¼ˆå¯é€‰ï¼‰
    """
    try:
        df = df.copy()
        
        # ç¡®ä¿æœ‰æ—¥æœŸåˆ—
        if 'date' not in df.columns and 'DATE' not in df.columns:
            print("è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ°æ—¥æœŸåˆ—ï¼Œæ— æ³•è¿›è¡Œå¹´èšåˆ")
            return df
            
        date_col = 'date' if 'date' in df.columns else 'DATE'
        df[date_col] = pd.to_datetime(df[date_col])
        
        # å¦‚æœæä¾›äº†æ—¥æœŸèŒƒå›´ï¼Œå…ˆè¿›è¡Œç­›é€‰
        if start_date is not None:
            # ç¡®ä¿start_dateæ˜¯pandas datetimeç±»å‹
            start_date = pd.to_datetime(start_date)
            df = df[df[date_col] >= start_date]
            
        if end_date is not None:
            # ç¡®ä¿end_dateæ˜¯pandas datetimeç±»å‹
            end_date = pd.to_datetime(end_date)
            df = df[df[date_col] <= end_date]
        
        df.set_index(date_col, inplace=True)
        
        # å¹´èšåˆè§„åˆ™
        agg_rules = {
            'OPEN': 'first',     # å¼€ç›˜ä»·å–ç¬¬ä¸€å¤©
            'open': 'first',
            'HIGH': 'max',       # æœ€é«˜ä»·å–æœ€å¤§å€¼
            'high': 'max',
            'LOW': 'min',        # æœ€ä½ä»·å–æœ€å°å€¼
            'low': 'min',
            'CLOSE': 'last',     # æ”¶ç›˜ä»·å–æœ€åä¸€å¤©
            'close': 'last',
            'VOLUME': 'sum',     # æˆäº¤é‡ç´¯åŠ 
            'volume': 'sum',
            'AMOUNT': 'sum',     # æˆäº¤é¢ç´¯åŠ 
            'amount': 'sum',
            'turnover': 'sum',
            'code': 'first',     # è‚¡ç¥¨ä»£ç å–ç¬¬ä¸€ä¸ª
            'name': 'first',     # è‚¡ç¥¨åç§°å–ç¬¬ä¸€ä¸ª
            'change': 'last',    # å˜åŒ–é¢å–æœ€åä¸€å¤©
            'change_rate': 'last', # å˜åŒ–ç‡å–æœ€åä¸€å¤©
            'amplitude': 'max',   # æŒ¯å¹…å–æœ€å¤§å€¼
            'turnover_rate': 'sum' # æ¢æ‰‹ç‡ç´¯åŠ 
        }
        
        # åªèšåˆå­˜åœ¨çš„åˆ—
        existing_agg_rules = {k: v for k, v in agg_rules.items() if k in df.columns}
        
        if existing_agg_rules:
            # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„è¿›è¡Œèšåˆ
            if 'code' in df.columns:
                # å…ˆæŒ‰codeåˆ†ç»„ï¼Œå†å¯¹æ¯ç»„è¿›è¡Œå¹´èšåˆ
                grouped_dfs = []
                for code, group in df.groupby('code'):
                    group_copy = group.copy()
                    # å¯¹æ¯åªè‚¡ç¥¨å•ç‹¬è¿›è¡Œå¹´èšåˆ
                    yearly_group = group_copy.resample('YE').agg(existing_agg_rules)
                    yearly_group.reset_index(inplace=True)
                    # ç¡®ä¿è‚¡ç¥¨ä»£ç æ­£ç¡®ä¼ é€’
                    yearly_group['code'] = code
                    if 'name' in group_copy.columns:
                        yearly_group['name'] = group_copy['name'].iloc[0]
                    grouped_dfs.append(yearly_group)
                
                if grouped_dfs:
                    yearly_df = pd.concat(grouped_dfs, ignore_index=True)
                    print(f"æˆåŠŸå°† {len(df)} è¡Œæ—¥æ•°æ®èšåˆä¸º {len(yearly_df)} è¡Œå¹´æ•°æ®")
                    return yearly_df
            else:
                yearly_df = df.resample('YE').agg(existing_agg_rules)
                yearly_df.reset_index(inplace=True)
                print(f"æˆåŠŸå°† {len(df)} è¡Œæ—¥æ•°æ®èšåˆä¸º {len(yearly_df)} è¡Œå¹´æ•°æ®")
                return yearly_df
        else:
            print("è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ°å¯èšåˆçš„OHLCVåˆ—")
            return df
            
    except Exception as e:
        print(f"å¹´èšåˆå¤±è´¥: {e}")
        print(f"é”™è¯¯è¯¦ç»†ä¿¡æ¯: start_dateç±»å‹={type(start_date)}, end_dateç±»å‹={type(end_date)}")
        import traceback
        traceback.print_exc()
        return df


def compress_stock_results(df, compress_by_stock=True):
    """
    å‹ç¼©è‚¡ç¥¨ç­›é€‰ç»“æœï¼Œå°†åŒä¸€åªè‚¡ç¥¨çš„å¤šæ¡è®°å½•åˆå¹¶ä¸ºä¸€æ¡
    
    Args:
        df: ç­›é€‰ç»“æœDataFrame
        compress_by_stock: æ˜¯å¦æŒ‰è‚¡ç¥¨ä»£ç å‹ç¼©ï¼Œé»˜è®¤True
    
    Returns:
        å‹ç¼©åçš„DataFrameå’Œç»Ÿè®¡ä¿¡æ¯
    """
    if not compress_by_stock or len(df) == 0:
        return df, {
            'compressed': False,
            'original_records': len(df),
            'unique_stocks': len(df['code'].unique()) if 'code' in df.columns else 0,
            'compression_ratio': 1.0
        }
    
    try:
        # ç¡®ä¿æœ‰è‚¡ç¥¨ä»£ç åˆ—
        if 'code' not in df.columns:
            print("è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ°è‚¡ç¥¨ä»£ç åˆ—ï¼Œæ— æ³•è¿›è¡Œå‹ç¼©")
            return df, {
                'compressed': False,
                'original_records': len(df),
                'unique_stocks': 0,
                'compression_ratio': 1.0
            }
        
        print(f"å¼€å§‹å‹ç¼©è‚¡ç¥¨ç»“æœï¼ŒåŸå§‹è®°å½•æ•°: {len(df)}")
        
        # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„
        compressed_results = []
        compression_stats = {
            'stock_details': {}
        }
        
        for code, group in df.groupby('code'):
            # è·å–è¯¥è‚¡ç¥¨çš„åŸºæœ¬ä¿¡æ¯ï¼ˆå–æœ€æ–°çš„è®°å½•ï¼‰
            if 'date' in group.columns:
                # æŒ‰æ—¥æœŸæ’åºï¼Œå–æœ€æ–°çš„è®°å½•ä½œä¸ºåŸºå‡†
                group_sorted = group.sort_values('date', ascending=False)
                latest_record = group_sorted.iloc[0].copy()
            else:
                # å¦‚æœæ²¡æœ‰æ—¥æœŸåˆ—ï¼Œå–ç¬¬ä¸€æ¡è®°å½•
                latest_record = group.iloc[0].copy()
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            latest_record['data_points'] = len(group)  # è¯¥è‚¡ç¥¨çš„æ•°æ®ç‚¹æ•°é‡
            latest_record['date_range_start'] = group['date'].min() if 'date' in group.columns else None
            latest_record['date_range_end'] = group['date'].max() if 'date' in group.columns else None
            
            # è®¡ç®—è¯¥è‚¡ç¥¨åœ¨æ—¶é—´èŒƒå›´å†…çš„ç»Ÿè®¡æŒ‡æ ‡
            if 'close' in group.columns:
                latest_record['period_high'] = group['close'].max()
                latest_record['period_low'] = group['close'].min()
                latest_record['period_avg'] = group['close'].mean()
            
            # ä¿ç•™æŒ‡æ ‡çš„å¹³å‡å€¼ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            indicator_columns = [col for col in group.columns if col.startswith(('ma', 'macd', 'kdj', 'rsi', 'boll', 'cci', 'wr'))]
            for col in indicator_columns:
                if group[col].notna().any():
                    latest_record[f'{col}_avg'] = group[col].mean()
                    latest_record[f'{col}_latest'] = group[col].iloc[-1] if not group[col].isna().all() else None
            
            compressed_results.append(latest_record)
            
            # è®°å½•å‹ç¼©ç»Ÿè®¡ä¿¡æ¯
            compression_stats['stock_details'][code] = {
                'original_records': len(group),
                'date_range': f"{group['date'].min()} è‡³ {group['date'].max()}" if 'date' in group.columns else "æ— æ—¥æœŸä¿¡æ¯"
            }
        
        # åˆ›å»ºå‹ç¼©åçš„DataFrame
        if compressed_results:
            compressed_df = pd.DataFrame(compressed_results)
        else:
            compressed_df = pd.DataFrame()
        
        # è®¡ç®—å‹ç¼©ç»Ÿè®¡ä¿¡æ¯
        original_count = len(df)
        compressed_count = len(compressed_df)
        unique_stocks = len(df['code'].unique())
        
        stats = {
            'compressed': True,
            'original_records': original_count,
            'compressed_records': compressed_count,
            'unique_stocks': unique_stocks,
            'compression_ratio': original_count / compressed_count if compressed_count > 0 else 0,
            'compression_details': compression_stats['stock_details']
        }
        
        print(f"å‹ç¼©å®Œæˆ: {original_count} æ¡è®°å½• â†’ {compressed_count} æ¡è®°å½• (å‹ç¼©æ¯”: {stats['compression_ratio']:.1f}:1)")
        print(f"æ¶‰åŠ {unique_stocks} åªä¸åŒè‚¡ç¥¨")
        
        return compressed_df, stats
        
    except Exception as e:
        print(f"å‹ç¼©è‚¡ç¥¨ç»“æœæ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return df, {
            'compressed': False,
            'original_records': len(df),
            'unique_stocks': len(df['code'].unique()) if 'code' in df.columns else 0,
            'compression_ratio': 1.0,
            'error': str(e)
        }


@csrf_exempt
def advanced_analysis_api(request):
    """
    é«˜çº§æŠ€æœ¯åˆ†æAPIæ¥å£
    æ”¯æŒMACD/KDJèƒŒç¦»åˆ†æã€å¤šç©ºä¿¡å·è¯†åˆ«ã€å¸‚åœºåˆ†æç­‰åŠŸèƒ½
    """
    if request.method == 'POST':
        try:
            data = json.loads(request.body.decode('utf-8'))
            
            # è·å–åŸºæœ¬å‚æ•°
            stock_codes = data.get('stock_codes', [])
            start_date = data.get('start_date')
            end_date = data.get('end_date')
            market_filter = data.get('market', 'ALL')  # å¸‚åœºç­›é€‰ï¼šshanghai/shenzhen/ALL
            
            # è·å–åˆ†æå‚æ•°
            enable_divergence = data.get('enable_divergence', True)
            enable_trend_signals = data.get('enable_trend_signals', True)
            enable_market_analysis = data.get('enable_market_analysis', True)
            
            # è·å–æŒ‡æ ‡å‚æ•°
            macd_params = data.get('macd_params', {'short': 12, 'long': 26, 'signal': 9})
            kdj_params = data.get('kdj_params', {'n': 9, 'k_factor': 2/3, 'd_factor': 2/3})
            
            print(f"é«˜çº§åˆ†æè¯·æ±‚ - è‚¡ç¥¨æ•°é‡: {len(stock_codes)}, å¸‚åœº: {market_filter}")
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šè‚¡ç¥¨ä»£ç ï¼Œä»æ•°æ®åº“è·å–
            if not stock_codes:
                queryset = StockHistoryData.objects.all()
                if start_date:
                    if isinstance(start_date, str):
                        start_date = datetime.strptime(start_date.replace('-', ''), '%Y%m%d').date()
                    queryset = queryset.filter(date__gte=start_date)
                
                if end_date:
                    if isinstance(end_date, str):
                        end_date = datetime.strptime(end_date.replace('-', ''), '%Y%m%d').date()
                    queryset = queryset.filter(date__lte=end_date)
                
                stock_codes = list(queryset.values_list('symbol', flat=True).distinct()[:50])
            
            # å¸‚åœºç­›é€‰
            if market_filter != 'ALL':
                if market_filter.lower() in ['shanghai', 'sh', 'ä¸Šè¯']:
                    stock_codes = MarketAnalyzer.filter_stocks_by_market(stock_codes, 'shanghai')
                elif market_filter.lower() in ['shenzhen', 'sz', 'æ·±è¯']:
                    stock_codes = MarketAnalyzer.filter_stocks_by_market(stock_codes, 'shenzhen')
            
            print(f"å¸‚åœºç­›é€‰åè‚¡ç¥¨æ•°é‡: {len(stock_codes)}")
            
            # åˆ†æç»“æœ
            analysis_results = {
                'market_analysis': {},
                'stocks_analysis': {},
                'summary': {}
            }
            
            # å¸‚åœºåˆ†æ
            if enable_market_analysis:
                market_analysis = get_market_analysis_summary(
                    stock_codes, 
                    market_filter.lower() if market_filter != 'ALL' else None
                )
                analysis_results['market_analysis'] = market_analysis
            
            # è‚¡ç¥¨ä¸ªè‚¡åˆ†æ
            processed_count = 0
            for code in stock_codes[:20]:  # é™åˆ¶å¤„ç†æ•°é‡
                try:
                    # è·å–è‚¡ç¥¨æ•°æ®
                    queryset = StockHistoryData.objects.filter(symbol=code)
                    if start_date:
                        queryset = queryset.filter(date__gte=start_date)
                    if end_date:
                        queryset = queryset.filter(date__lte=end_date)
                    
                    data_records = list(queryset.values(
                        'date', 'symbol', 'open', 'close', 'high', 'low', 'volume'
                    ))
                    
                    if len(data_records) < 20:  # æ•°æ®ä¸è¶³
                        continue
                    
                    # è½¬æ¢ä¸ºDataFrame
                    stock_df = pd.DataFrame(data_records)
                    stock_df = stock_df.rename(columns={
                        'symbol': 'code',
                        'open': 'open',
                        'close': 'close', 
                        'high': 'high',
                        'low': 'low'
                    })
                    
                    # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸæ’åº
                    stock_df['date'] = pd.to_datetime(stock_df['date'])
                    stock_df = stock_df.sort_values('date').reset_index(drop=True)
                    
                    # åˆ›å»ºè‚¡ç¥¨åˆ†æç»“æœ
                    stock_analysis = {
                        'code': code,
                        'market': MarketAnalyzer.identify_market(code),
                        'sector': MarketAnalyzer.identify_sector(code),
                        'data_points': len(stock_df),
                        'date_range': {
                            'start': stock_df['date'].min().strftime('%Y-%m-%d'),
                            'end': stock_df['date'].max().strftime('%Y-%m-%d')
                        }
                    }
                    
                    # MACDèƒŒç¦»åˆ†æ
                    if enable_divergence:
                        macd_divergence = analyze_macd_divergence(stock_df, **macd_params)
                        stock_analysis['macd_divergence'] = macd_divergence
                        
                        kdj_divergence = analyze_kdj_divergence(stock_df, **kdj_params)
                        stock_analysis['kdj_divergence'] = kdj_divergence
                    
                    # è¶‹åŠ¿ä¿¡å·åˆ†æ
                    if enable_trend_signals:
                        trend_signals = analyze_trend_signals(
                            stock_df, 
                            **macd_params,
                            n=kdj_params.get('n', 9)
                        )
                        stock_analysis['trend_signals'] = trend_signals
                    
                    analysis_results['stocks_analysis'][code] = stock_analysis
                    processed_count += 1
                    
                except Exception as e:
                    print(f"åˆ†æè‚¡ç¥¨ {code} æ—¶å‡ºé”™: {e}")
                    analysis_results['stocks_analysis'][code] = {
                        'code': code,
                        'error': str(e)
                    }
            
            # ç”Ÿæˆæ‘˜è¦
            analysis_results['summary'] = {
                'total_requested': len(stock_codes),
                'successfully_analyzed': processed_count,
                'market_filter': market_filter,
                'analysis_features': {
                    'divergence_analysis': enable_divergence,
                    'trend_signals': enable_trend_signals,
                    'market_analysis': enable_market_analysis
                }
            }
            
            print(f"å®Œæˆé«˜çº§åˆ†æ - å¤„ç† {processed_count} åªè‚¡ç¥¨")
            
            # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹ï¼Œè§£å†³JSONåºåˆ—åŒ–é—®é¢˜
            def convert_numpy_types(obj):
                if isinstance(obj, dict):
                    return {k: convert_numpy_types(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_numpy_types(v) for v in obj]
                elif hasattr(obj, 'item'):  # numpyç±»å‹
                    return obj.item()
                elif hasattr(obj, 'tolist'):  # numpyæ•°ç»„
                    return obj.tolist()
                else:
                    return obj
            
            # è½¬æ¢æ‰€æœ‰æ•°æ®
            safe_analysis_results = convert_numpy_types(analysis_results)
            
            return JsonResponse({
                'success': True,
                'data': safe_analysis_results
            })
            
        except Exception as e:
            print(f"é«˜çº§åˆ†æAPIé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return JsonResponse({
                'success': False, 
                'error': str(e)
            })
    else:
        return JsonResponse({
            'success': False, 
            'error': 'Only POST method allowed'
        })
